{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final_model_Keras_without_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 1\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']= '0'\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "#tf.random.set_seed(seed_value)\n",
    "# for later versions: \n",
    "tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "from keras import backend as K\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "# for later versions:\n",
    "# session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "# sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "# tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "\n",
    "# Resource\n",
    "# https://stackoverflow.com/questions/45230448/how-to-get-reproducible-result-when-running-keras-with-tensorflow-backend?rq=1\n",
    "# https://stackoverflow.com/questions/32419510/how-to-get-reproducible-results-in-keras/52897216#52897216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "def get_ecfc(smiles_list, radius=2, nBits=2048, useCounts=True):\n",
    "    \"\"\"\n",
    "    Calculates the ECFP fingerprint for given SMILES list\n",
    "    \n",
    "    :param smiles_list: List of SMILES\n",
    "    :type smiles_list: list\n",
    "    :param radius: The ECPF fingerprints radius.\n",
    "    :type radius: int\n",
    "    :param nBits: The number of bits of the fingerprint vector.\n",
    "    :type nBits: int\n",
    "    :param useCounts: Use count vector or bit vector.\n",
    "    :type useCounts: bool\n",
    "    :returns: The calculated ECPF fingerprints for the given SMILES\n",
    "    :rtype: Dataframe\n",
    "    \"\"\"     \n",
    "    \n",
    "    ecfp_fingerprints=[]\n",
    "    erroneous_smiles=[]\n",
    "    for smiles in smiles_list:\n",
    "        mol=Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            ecfp_fingerprints.append([None]*nBits)\n",
    "            erroneous_smiles.append(smiles)\n",
    "        else:\n",
    "            mol=Chem.AddHs(mol)\n",
    "            if useCounts:\n",
    "                ecfp_fingerprints.append(list(AllChem.GetHashedMorganFingerprint(mol, radius, nBits)))  \n",
    "            else:    \n",
    "                ecfp_fingerprints.append(list(AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits).ToBitString()))  \n",
    "    \n",
    "    # Create dataframe of fingerprints\n",
    "    df_ecfp_fingerprints = pd.DataFrame(data = ecfp_fingerprints, index = smiles_list)\n",
    "    # Remove erroneous data\n",
    "    if len(erroneous_smiles)>0:\n",
    "        print(\"The following erroneous SMILES have been found in the data:\\n{}.\\nThe erroneous SMILES will be removed from the data.\".format('\\n'.join(map(str, erroneous_smiles))))           \n",
    "        df_ecfp_fingerprints = df_ecfp_fingerprints.dropna(how='any')    \n",
    "    \n",
    "    return df_ecfp_fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get and Arrange data\n",
    "import pandas as pd\n",
    "df_data= pd.read_csv('all_data.csv')\n",
    "\n",
    "train_data = df_data[df_data['data_type'] == 0]\n",
    "test1_data = df_data[df_data['data_type'] == 1]\n",
    "test2_data = df_data[df_data['data_type'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded = get_ecfc(train_data[\"reactant_smiles\"])\n",
    "test1_encoded = get_ecfc(test1_data[\"reactant_smiles\"])\n",
    "test2_encoded = get_ecfc(test2_data[\"reactant_smiles\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def modeling(train_data, test1_data, test2_data, encoder, model):  - After deciding the list of the smiles\n",
    "\n",
    "def modeling(train_encoded, test1_encoded, test2_encoded, model):\n",
    "    \n",
    "    from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Training\n",
    "    X = train_encoded\n",
    "    y = train_data['reaction_energy']\n",
    "    \n",
    "    model.fit(X.values, y)\n",
    "    \n",
    "    # Predicting\n",
    "    pred_train = model.predict(train_encoded.values)\n",
    "    pred_test1 = model.predict(test1_encoded.values)\n",
    "    pred_test2 = model.predict(test2_encoded.values)\n",
    "    \n",
    "    \n",
    "    # Scores of Train Data \n",
    "    tr_mae = mean_absolute_error(y, pred_train)\n",
    "    tr_rmse = mean_squared_error(y ,pred_train , squared=False)\n",
    "    tr_r2 = r2_score(y, pred_train)\n",
    "    print('##########################  Scores of Train Data  ##########################')\n",
    "    print('Train set MAE of {}: {:.3f}'.format(model, tr_mae))\n",
    "    print('Train set RMSE of {}: {:.3f}'.format(model, tr_rmse))\n",
    "    print('Train set R2 Score of {}: {:.3f}'.format(model, tr_r2))\n",
    "    \n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    \n",
    "    # Test1 Data\n",
    "    test1_mae = mean_absolute_error(test1_data['reaction_energy'], pred_test1)\n",
    "    test1_rmse = mean_squared_error(test1_data['reaction_energy'], pred_test1, squared=False)\n",
    "    test1_r2 = r2_score(test1_data['reaction_energy'], pred_test1)\n",
    "    print('##########################  Scores of Test1 Data  ##########################')\n",
    "    print('Test1 set MAE of {}: {:.3f}'.format(model, test1_mae))\n",
    "    print('Test1 set RMSE of {}: {:.3f}'.format(model, test1_rmse))\n",
    "    print('Test1 set R2 Score of {}: {:.3f}'.format(model, test1_r2))\n",
    "    \n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    \n",
    "    # Test2 Data\n",
    "    test2_mae = mean_absolute_error(test2_data['reaction_energy'], pred_test2)\n",
    "    test2_rmse = mean_squared_error(test2_data['reaction_energy'], pred_test2, squared=False)\n",
    "    test2_r2 = r2_score(test2_data['reaction_energy'], pred_test2)\n",
    "    print('##########################  Scores of Test2 Data  ##########################')\n",
    "    print('Test2 set MAE of {}: {:.3f}'.format(model, test2_mae))\n",
    "    print('Test2 set RMSE of {}: {:.3f}'.format(model, test2_rmse))\n",
    "    print('Test2 set R2 Score of {}: {:.3f}'.format(model, test2_r2))\n",
    "    \n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('##########################  Details  ##########################')\n",
    "    print(f'{elapsed_time:.2f}s elapsed during modeling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIAL RUNNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "def BuildModel(input_dim=None):\n",
    "    \n",
    "    def model():\n",
    "        keras_model = Sequential()\n",
    "        keras_model.add(Dense(128, input_dim=input_dim,activation='relu')) \n",
    "        keras_model.add(Dense(32, activation='relu')) \n",
    "        keras_model.add(Dense(8,activation='relu')) \n",
    "        keras_model.add(Dense(1,activation='linear'))\n",
    "        keras_model.summary()\n",
    "        keras_model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")   \n",
    "        return keras_model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 266,673\n",
      "Trainable params: 266,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "12707/12707 [==============================] - 16s 1ms/step - loss: 5.2006e-04\n",
      "Epoch 2/10\n",
      "12707/12707 [==============================] - 13s 1000us/step - loss: 9.0461e-05\n",
      "Epoch 3/10\n",
      "12707/12707 [==============================] - 12s 961us/step - loss: 8.3207e-05\n",
      "Epoch 4/10\n",
      "12707/12707 [==============================] - 11s 895us/step - loss: 7.8996e-05\n",
      "Epoch 5/10\n",
      "12707/12707 [==============================] - 13s 997us/step - loss: 8.1842e-05\n",
      "Epoch 6/10\n",
      "12707/12707 [==============================] - 13s 1ms/step - loss: 7.3577e-05\n",
      "Epoch 7/10\n",
      "12707/12707 [==============================] - 14s 1ms/step - loss: 6.8772e-05\n",
      "Epoch 8/10\n",
      "12707/12707 [==============================] - 14s 1ms/step - loss: 6.7166e-05\n",
      "Epoch 9/10\n",
      "12707/12707 [==============================] - 18s 1ms/step - loss: 6.1988e-05\n",
      "Epoch 10/10\n",
      "12707/12707 [==============================] - 15s 1ms/step - loss: 6.3266e-05\n",
      "##########################  Scores of Train Data  ##########################\n",
      "Train set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.004\n",
      "Train set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.007\n",
      "Train set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.967\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Scores of Test1 Data  ##########################\n",
      "Test1 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.004\n",
      "Test1 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.008\n",
      "Test1 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.963\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Scores of Test2 Data  ##########################\n",
      "Test2 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.006\n",
      "Test2 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.008\n",
      "Test2 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.925\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Details  ##########################\n",
      "140.82s elapsed during modeling\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "#input_dim = 2048\n",
    "#model = KerasRegressor(build_fn=BuildModel(input_dim = 2048), nb_epoch=100, batch_size=3)\n",
    "model = KerasRegressor(build_fn=BuildModel(input_dim = 2048), epochs=10, batch_size=5)\n",
    "\n",
    "\n",
    "# Training\n",
    "#np.random.seed(123)\n",
    "modeling(train_encoded=train_encoded, test1_encoded=test1_encoded, test2_encoded=test2_encoded, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 10/10\n",
    "12707/12707 [==============================] - 15s 1ms/step - loss: 6.3266e-05\n",
    "##########################  Scores of Train Data  ##########################\n",
    "Train set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.004\n",
    "Train set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.007\n",
    "Train set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.967\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Scores of Test1 Data  ##########################\n",
    "Test1 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.004\n",
    "Test1 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.008\n",
    "Test1 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.963\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Scores of Test2 Data  ##########################\n",
    "Test2 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.006\n",
    "Test2 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.008\n",
    "Test2 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.925\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Details  ##########################\n",
    "140.82s elapsed during modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- This is for after Lasso FS !!!  --------   Final Best: 0.957283 using {'activation': 'sigmoid', 'batch_size': 16, 'dropout_rate': 0.0, 'input_dim': 491, 'learn_rate': 0.1, 'momentum': 0.4, 'optimizer': 'RMSprop'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "# Function to create model, required for KerasClassifier\n",
    "\n",
    "\n",
    "def create_model(optimizer='RMSprop', learn_rate=0.1, momentum=0.4, activation='sigmoid', dropout_rate=0.0):\n",
    "    \n",
    "    keras_model = Sequential()\n",
    "    keras_model.add(Dense(128, input_dim=train_encoded.shape[1], activation=activation))\n",
    "    keras_model.add(Dropout(dropout_rate))\n",
    "    keras_model.add(Dense(32, activation=activation)) \n",
    "    keras_model.add(Dropout(dropout_rate))\n",
    "    keras_model.add(Dense(8,activation=activation)) \n",
    "    keras_model.add(Dropout(dropout_rate))\n",
    "    keras_model.add(Dense(1,activation='linear'))\n",
    "    keras_model.summary()\n",
    "    # Compile model\n",
    "    keras_model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "    return keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 266,673\n",
      "Trainable params: 266,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/300\n",
      "12707/12707 [==============================] - 4s 286us/step - loss: 0.0171\n",
      "Epoch 2/300\n",
      "12707/12707 [==============================] - 4s 337us/step - loss: 1.7111e-04\n",
      "Epoch 3/300\n",
      "12707/12707 [==============================] - 4s 326us/step - loss: 1.3981e-04\n",
      "Epoch 4/300\n",
      "12707/12707 [==============================] - 4s 320us/step - loss: 1.2529e-04\n",
      "Epoch 5/300\n",
      "12707/12707 [==============================] - 4s 351us/step - loss: 1.1569e-04\n",
      "Epoch 6/300\n",
      "12707/12707 [==============================] - 4s 330us/step - loss: 1.0844e-04\n",
      "Epoch 7/300\n",
      "12707/12707 [==============================] - 4s 320us/step - loss: 1.0385e-04\n",
      "Epoch 8/300\n",
      "12707/12707 [==============================] - 4s 314us/step - loss: 9.7896e-05\n",
      "Epoch 9/300\n",
      "12707/12707 [==============================] - 4s 344us/step - loss: 9.3976e-05\n",
      "Epoch 10/300\n",
      "12707/12707 [==============================] - 4s 316us/step - loss: 9.2665e-05\n",
      "Epoch 11/300\n",
      "12707/12707 [==============================] - 4s 315us/step - loss: 9.1331e-05\n",
      "Epoch 12/300\n",
      "12707/12707 [==============================] - 4s 279us/step - loss: 8.7552e-05\n",
      "Epoch 13/300\n",
      "12707/12707 [==============================] - 4s 352us/step - loss: 8.7074e-05\n",
      "Epoch 14/300\n",
      "12707/12707 [==============================] - 5s 367us/step - loss: 8.5883e-05\n",
      "Epoch 15/300\n",
      "12707/12707 [==============================] - 5s 360us/step - loss: 8.4386e-05\n",
      "Epoch 16/300\n",
      "12707/12707 [==============================] - 4s 341us/step - loss: 8.3077e-05\n",
      "Epoch 17/300\n",
      "12707/12707 [==============================] - 5s 366us/step - loss: 8.2546e-05\n",
      "Epoch 18/300\n",
      "12707/12707 [==============================] - 4s 342us/step - loss: 8.1406e-05\n",
      "Epoch 19/300\n",
      "12707/12707 [==============================] - 4s 341us/step - loss: 7.9738e-05\n",
      "Epoch 20/300\n",
      "12707/12707 [==============================] - 4s 340us/step - loss: 7.9303e-05\n",
      "Epoch 21/300\n",
      "12707/12707 [==============================] - 5s 362us/step - loss: 7.8638e-05\n",
      "Epoch 22/300\n",
      "12707/12707 [==============================] - 5s 360us/step - loss: 7.6990e-05\n",
      "Epoch 23/300\n",
      "12707/12707 [==============================] - 4s 329us/step - loss: 7.7342e-05 0s - loss: 7\n",
      "Epoch 24/300\n",
      "12707/12707 [==============================] - 4s 351us/step - loss: 7.5545e-05\n",
      "Epoch 25/300\n",
      "12707/12707 [==============================] - 5s 368us/step - loss: 7.4862e-05\n",
      "Epoch 26/300\n",
      "12707/12707 [==============================] - 4s 348us/step - loss: 7.4446e-05\n",
      "Epoch 27/300\n",
      "12707/12707 [==============================] - 5s 379us/step - loss: 7.4366e-05\n",
      "Epoch 28/300\n",
      "12707/12707 [==============================] - 5s 368us/step - loss: 7.3540e-05\n",
      "Epoch 29/300\n",
      "12707/12707 [==============================] - 5s 372us/step - loss: 7.3442e-05\n",
      "Epoch 30/300\n",
      "12707/12707 [==============================] - 4s 348us/step - loss: 7.2546e-05\n",
      "Epoch 31/300\n",
      "12707/12707 [==============================] - 5s 379us/step - loss: 7.2348e-05\n",
      "Epoch 32/300\n",
      "12707/12707 [==============================] - 5s 388us/step - loss: 7.1454e-05\n",
      "Epoch 33/300\n",
      "12707/12707 [==============================] - 4s 346us/step - loss: 7.1651e-05\n",
      "Epoch 34/300\n",
      "12707/12707 [==============================] - 5s 356us/step - loss: 7.1659e-05\n",
      "Epoch 35/300\n",
      "12707/12707 [==============================] - 3s 253us/step - loss: 7.0697e-05\n",
      "Epoch 36/300\n",
      "12707/12707 [==============================] - 3s 269us/step - loss: 7.0740e-05\n",
      "Epoch 37/300\n",
      "12707/12707 [==============================] - 3s 247us/step - loss: 7.0002e-05\n",
      "Epoch 38/300\n",
      "12707/12707 [==============================] - 4s 317us/step - loss: 6.9541e-05\n",
      "Epoch 39/300\n",
      "12707/12707 [==============================] - 5s 374us/step - loss: 6.9368e-05\n",
      "Epoch 40/300\n",
      "12707/12707 [==============================] - 4s 354us/step - loss: 7.0094e-05\n",
      "Epoch 41/300\n",
      "12707/12707 [==============================] - 4s 342us/step - loss: 6.9353e-05\n",
      "Epoch 42/300\n",
      "12707/12707 [==============================] - 5s 365us/step - loss: 6.9752e-05\n",
      "Epoch 43/300\n",
      "12707/12707 [==============================] - 4s 342us/step - loss: 6.8278e-05\n",
      "Epoch 44/300\n",
      "12707/12707 [==============================] - 5s 365us/step - loss: 6.7998e-05\n",
      "Epoch 45/300\n",
      "12707/12707 [==============================] - 4s 338us/step - loss: 6.8868e-05\n",
      "Epoch 46/300\n",
      "12707/12707 [==============================] - 5s 361us/step - loss: 6.8480e-05\n",
      "Epoch 47/300\n",
      "12707/12707 [==============================] - 5s 373us/step - loss: 6.6846e-05\n",
      "Epoch 48/300\n",
      "12707/12707 [==============================] - 5s 357us/step - loss: 6.7062e-05\n",
      "Epoch 49/300\n",
      "12707/12707 [==============================] - 5s 362us/step - loss: 6.7832e-05\n",
      "Epoch 50/300\n",
      "12707/12707 [==============================] - 4s 350us/step - loss: 6.7236e-05\n",
      "Epoch 51/300\n",
      "12707/12707 [==============================] - 5s 365us/step - loss: 6.6307e-05\n",
      "Epoch 52/300\n",
      "12707/12707 [==============================] - 5s 378us/step - loss: 6.6994e-05\n",
      "Epoch 53/300\n",
      "12707/12707 [==============================] - 5s 377us/step - loss: 6.5731e-05\n",
      "Epoch 54/300\n",
      "12707/12707 [==============================] - 5s 370us/step - loss: 6.5736e-05\n",
      "Epoch 55/300\n",
      "12707/12707 [==============================] - 4s 342us/step - loss: 6.6361e-05\n",
      "Epoch 56/300\n",
      "12707/12707 [==============================] - 5s 360us/step - loss: 6.5717e-05\n",
      "Epoch 57/300\n",
      "12707/12707 [==============================] - 4s 337us/step - loss: 6.5788e-05\n",
      "Epoch 58/300\n",
      "12707/12707 [==============================] - 4s 342us/step - loss: 6.5132e-05\n",
      "Epoch 59/300\n",
      "12707/12707 [==============================] - 4s 318us/step - loss: 6.4830e-05\n",
      "Epoch 60/300\n",
      "12707/12707 [==============================] - 4s 277us/step - loss: 6.5101e-05\n",
      "Epoch 61/300\n",
      "12707/12707 [==============================] - 4s 294us/step - loss: 6.5319e-05\n",
      "Epoch 62/300\n",
      "12707/12707 [==============================] - 4s 310us/step - loss: 6.5308e-05\n",
      "Epoch 63/300\n",
      "12707/12707 [==============================] - 3s 273us/step - loss: 6.5373e-05\n",
      "Epoch 64/300\n",
      "12707/12707 [==============================] - 3s 271us/step - loss: 6.5064e-05\n",
      "Epoch 65/300\n",
      "12707/12707 [==============================] - 3s 253us/step - loss: 6.4736e-05\n",
      "Epoch 66/300\n",
      "12707/12707 [==============================] - 3s 253us/step - loss: 6.3955e-05\n",
      "Epoch 67/300\n",
      "12707/12707 [==============================] - 3s 253us/step - loss: 6.3963e-05\n",
      "Epoch 68/300\n",
      "12707/12707 [==============================] - 4s 277us/step - loss: 6.3691e-05\n",
      "Epoch 69/300\n",
      "12707/12707 [==============================] - 4s 279us/step - loss: 6.3015e-05\n",
      "Epoch 70/300\n",
      "12707/12707 [==============================] - 3s 272us/step - loss: 6.3204e-05\n",
      "Epoch 71/300\n",
      "12707/12707 [==============================] - 3s 275us/step - loss: 6.2965e-05\n",
      "Epoch 72/300\n",
      "12707/12707 [==============================] - 3s 271us/step - loss: 6.2001e-05\n",
      "Epoch 73/300\n",
      "12707/12707 [==============================] - 3s 255us/step - loss: 6.2791e-05\n",
      "Epoch 74/300\n",
      "12707/12707 [==============================] - 4s 277us/step - loss: 6.2948e-05\n",
      "Epoch 75/300\n",
      "12707/12707 [==============================] - 3s 257us/step - loss: 6.2076e-05\n",
      "Epoch 76/300\n",
      "12707/12707 [==============================] - 3s 256us/step - loss: 6.2650e-05\n",
      "Epoch 77/300\n",
      "12707/12707 [==============================] - 3s 246us/step - loss: 6.2794e-05\n",
      "Epoch 78/300\n",
      "12707/12707 [==============================] - 3s 249us/step - loss: 6.1644e-05\n",
      "Epoch 79/300\n",
      "12707/12707 [==============================] - 3s 253us/step - loss: 6.2975e-05\n",
      "Epoch 80/300\n",
      "12707/12707 [==============================] - 3s 247us/step - loss: 6.2149e-05\n",
      "Epoch 81/300\n",
      "12707/12707 [==============================] - 3s 243us/step - loss: 6.2702e-05\n",
      "Epoch 82/300\n",
      "12707/12707 [==============================] - 3s 243us/step - loss: 6.1509e-05\n",
      "Epoch 83/300\n",
      "12707/12707 [==============================] - 3s 247us/step - loss: 6.1003e-05\n",
      "Epoch 84/300\n",
      "12707/12707 [==============================] - 3s 253us/step - loss: 6.1660e-05\n",
      "Epoch 85/300\n",
      "12707/12707 [==============================] - 3s 251us/step - loss: 6.1050e-05\n",
      "Epoch 86/300\n",
      "12707/12707 [==============================] - 3s 242us/step - loss: 6.1323e-05\n",
      "Epoch 87/300\n",
      "12707/12707 [==============================] - 3s 245us/step - loss: 6.1336e-05\n",
      "Epoch 88/300\n",
      "12707/12707 [==============================] - 3s 248us/step - loss: 6.0933e-05\n",
      "Epoch 89/300\n",
      "12707/12707 [==============================] - 3s 269us/step - loss: 5.9990e-05\n",
      "Epoch 90/300\n",
      "12707/12707 [==============================] - 3s 274us/step - loss: 6.0469e-05\n",
      "Epoch 91/300\n",
      "12707/12707 [==============================] - 3s 267us/step - loss: 6.1231e-05\n",
      "Epoch 92/300\n",
      "12707/12707 [==============================] - 3s 270us/step - loss: 6.0484e-05\n",
      "Epoch 93/300\n",
      "12707/12707 [==============================] - 3s 248us/step - loss: 5.9728e-05\n",
      "Epoch 94/300\n",
      "12707/12707 [==============================] - 3s 255us/step - loss: 5.9914e-05\n",
      "Epoch 95/300\n",
      "12707/12707 [==============================] - 3s 250us/step - loss: 6.0428e-05\n",
      "Epoch 96/300\n",
      "12707/12707 [==============================] - 3s 249us/step - loss: 6.0598e-05\n",
      "Epoch 97/300\n",
      "12707/12707 [==============================] - 3s 264us/step - loss: 6.0222e-05\n",
      "Epoch 98/300\n",
      "12707/12707 [==============================] - 3s 252us/step - loss: 6.0467e-05\n",
      "Epoch 99/300\n",
      "12707/12707 [==============================] - 3s 258us/step - loss: 5.9676e-05\n",
      "Epoch 100/300\n",
      "12707/12707 [==============================] - 4s 288us/step - loss: 6.0107e-05\n",
      "Epoch 101/300\n",
      "12707/12707 [==============================] - 4s 342us/step - loss: 6.0314e-05\n",
      "Epoch 102/300\n",
      "12707/12707 [==============================] - 5s 362us/step - loss: 5.8899e-05\n",
      "Epoch 103/300\n",
      "12707/12707 [==============================] - 5s 368us/step - loss: 5.9943e-05\n",
      "Epoch 104/300\n",
      "12707/12707 [==============================] - 5s 384us/step - loss: 5.9784e-05\n",
      "Epoch 105/300\n",
      "12707/12707 [==============================] - 4s 346us/step - loss: 6.0125e-05\n",
      "Epoch 106/300\n",
      "12707/12707 [==============================] - 4s 347us/step - loss: 5.9556e-05\n",
      "Epoch 107/300\n",
      "12707/12707 [==============================] - 4s 345us/step - loss: 5.9482e-05\n",
      "Epoch 108/300\n",
      "12707/12707 [==============================] - 4s 350us/step - loss: 5.9030e-05\n",
      "Epoch 109/300\n",
      "12707/12707 [==============================] - 4s 334us/step - loss: 6.0368e-05\n",
      "Epoch 110/300\n",
      "12707/12707 [==============================] - 5s 355us/step - loss: 5.8195e-05\n",
      "Epoch 111/300\n",
      "12707/12707 [==============================] - 4s 335us/step - loss: 5.8734e-05\n",
      "Epoch 112/300\n",
      "12707/12707 [==============================] - 4s 344us/step - loss: 5.7819e-05\n",
      "Epoch 113/300\n",
      "12707/12707 [==============================] - 5s 355us/step - loss: 5.8137e-05\n",
      "Epoch 114/300\n",
      "12707/12707 [==============================] - 4s 343us/step - loss: 5.8616e-05\n",
      "Epoch 115/300\n",
      "12707/12707 [==============================] - 5s 363us/step - loss: 5.8390e-05\n",
      "Epoch 116/300\n",
      "12707/12707 [==============================] - 4s 335us/step - loss: 5.7384e-05\n",
      "Epoch 117/300\n",
      "12707/12707 [==============================] - 4s 353us/step - loss: 5.6949e-05\n",
      "Epoch 118/300\n",
      "12707/12707 [==============================] - 4s 334us/step - loss: 5.6435e-05\n",
      "Epoch 119/300\n",
      "12707/12707 [==============================] - 4s 350us/step - loss: 5.5939e-05\n",
      "Epoch 120/300\n",
      "12707/12707 [==============================] - 4s 329us/step - loss: 5.6960e-05\n",
      "Epoch 121/300\n",
      "12707/12707 [==============================] - 4s 311us/step - loss: 5.7673e-05\n",
      "Epoch 122/300\n",
      "12707/12707 [==============================] - 4s 332us/step - loss: 5.6221e-05\n",
      "Epoch 123/300\n",
      "12707/12707 [==============================] - 4s 336us/step - loss: 5.7438e-05\n",
      "Epoch 124/300\n",
      "12707/12707 [==============================] - 4s 330us/step - loss: 5.5350e-05\n",
      "Epoch 125/300\n",
      "12707/12707 [==============================] - 4s 352us/step - loss: 5.5862e-05\n",
      "Epoch 126/300\n",
      "12707/12707 [==============================] - 4s 348us/step - loss: 5.6516e-05\n",
      "Epoch 127/300\n",
      "12707/12707 [==============================] - 5s 366us/step - loss: 5.5481e-05\n",
      "Epoch 128/300\n",
      "12707/12707 [==============================] - 4s 345us/step - loss: 5.5159e-05\n",
      "Epoch 129/300\n",
      "12707/12707 [==============================] - 4s 328us/step - loss: 5.5094e-05\n",
      "Epoch 130/300\n",
      "12707/12707 [==============================] - 5s 364us/step - loss: 5.4409e-05\n",
      "Epoch 131/300\n",
      "12707/12707 [==============================] - 4s 338us/step - loss: 5.4437e-05\n",
      "Epoch 132/300\n",
      "12707/12707 [==============================] - 4s 346us/step - loss: 5.4055e-05\n",
      "Epoch 133/300\n",
      "12707/12707 [==============================] - 4s 336us/step - loss: 5.5274e-05\n",
      "Epoch 134/300\n",
      "12707/12707 [==============================] - 4s 345us/step - loss: 5.2871e-05\n",
      "Epoch 135/300\n",
      "12707/12707 [==============================] - 4s 338us/step - loss: 5.4812e-05\n",
      "Epoch 136/300\n",
      "12707/12707 [==============================] - 4s 343us/step - loss: 5.2612e-05\n",
      "Epoch 137/300\n",
      "12707/12707 [==============================] - 5s 354us/step - loss: 5.3252e-05\n",
      "Epoch 138/300\n",
      "12707/12707 [==============================] - 4s 337us/step - loss: 5.3451e-05\n",
      "Epoch 139/300\n",
      "12707/12707 [==============================] - 4s 345us/step - loss: 5.2872e-05\n",
      "Epoch 140/300\n",
      "12707/12707 [==============================] - 4s 339us/step - loss: 5.4012e-05\n",
      "Epoch 141/300\n",
      "12707/12707 [==============================] - 5s 374us/step - loss: 5.3222e-05\n",
      "Epoch 142/300\n",
      "12707/12707 [==============================] - 4s 331us/step - loss: 5.2384e-05\n",
      "Epoch 143/300\n",
      "12707/12707 [==============================] - 4s 348us/step - loss: 5.1834e-05\n",
      "Epoch 144/300\n",
      "12707/12707 [==============================] - 5s 373us/step - loss: 5.0835e-05\n",
      "Epoch 145/300\n",
      "12707/12707 [==============================] - 4s 351us/step - loss: 5.1453e-05\n",
      "Epoch 146/300\n",
      "12707/12707 [==============================] - 4s 347us/step - loss: 5.1689e-05\n",
      "Epoch 147/300\n",
      "12707/12707 [==============================] - 4s 336us/step - loss: 5.1832e-05\n",
      "Epoch 148/300\n",
      "12707/12707 [==============================] - 5s 369us/step - loss: 5.1965e-05\n",
      "Epoch 149/300\n",
      "12707/12707 [==============================] - 4s 331us/step - loss: 4.9733e-05\n",
      "Epoch 150/300\n",
      "12707/12707 [==============================] - 5s 372us/step - loss: 5.0524e-05\n",
      "Epoch 151/300\n",
      "12707/12707 [==============================] - 5s 369us/step - loss: 4.9400e-05\n",
      "Epoch 152/300\n",
      "12707/12707 [==============================] - 4s 353us/step - loss: 4.8131e-05\n",
      "Epoch 153/300\n",
      "12707/12707 [==============================] - 4s 341us/step - loss: 4.9878e-05\n",
      "Epoch 154/300\n",
      "12707/12707 [==============================] - 5s 367us/step - loss: 4.9447e-05\n",
      "Epoch 155/300\n",
      "12707/12707 [==============================] - 5s 363us/step - loss: 4.9661e-05\n",
      "Epoch 156/300\n",
      "12707/12707 [==============================] - 4s 328us/step - loss: 4.9266e-05\n",
      "Epoch 157/300\n",
      "12707/12707 [==============================] - 5s 359us/step - loss: 4.9072e-05\n",
      "Epoch 158/300\n",
      "12707/12707 [==============================] - 4s 334us/step - loss: 4.8579e-05\n",
      "Epoch 159/300\n",
      "12707/12707 [==============================] - 4s 347us/step - loss: 4.9504e-05\n",
      "Epoch 160/300\n",
      "12707/12707 [==============================] - 4s 326us/step - loss: 5.0806e-05\n",
      "Epoch 161/300\n",
      "12707/12707 [==============================] - 4s 348us/step - loss: 4.9915e-05\n",
      "Epoch 162/300\n",
      "12707/12707 [==============================] - 5s 372us/step - loss: 4.7769e-05\n",
      "Epoch 163/300\n",
      "12707/12707 [==============================] - 5s 378us/step - loss: 4.8977e-05\n",
      "Epoch 164/300\n",
      "12707/12707 [==============================] - 4s 346us/step - loss: 4.7383e-05\n",
      "Epoch 165/300\n",
      "12707/12707 [==============================] - 5s 362us/step - loss: 4.8174e-05\n",
      "Epoch 166/300\n",
      "12707/12707 [==============================] - 3s 265us/step - loss: 4.7769e-05\n",
      "Epoch 167/300\n",
      "12707/12707 [==============================] - 3s 244us/step - loss: 4.8845e-05\n",
      "Epoch 168/300\n",
      "12707/12707 [==============================] - 3s 243us/step - loss: 4.6942e-05\n",
      "Epoch 169/300\n",
      "12707/12707 [==============================] - 3s 254us/step - loss: 4.8090e-05\n",
      "Epoch 170/300\n",
      "12707/12707 [==============================] - 3s 241us/step - loss: 4.7514e-05\n",
      "Epoch 171/300\n",
      "12707/12707 [==============================] - 3s 243us/step - loss: 4.8246e-05\n",
      "Epoch 172/300\n",
      "12707/12707 [==============================] - 3s 241us/step - loss: 4.6542e-05\n",
      "Epoch 173/300\n",
      "12707/12707 [==============================] - 3s 248us/step - loss: 4.5583e-05\n",
      "Epoch 174/300\n",
      "12707/12707 [==============================] - 3s 255us/step - loss: 4.7750e-05\n",
      "Epoch 175/300\n",
      "12707/12707 [==============================] - 3s 242us/step - loss: 4.6915e-05\n",
      "Epoch 176/300\n",
      "12707/12707 [==============================] - 4s 302us/step - loss: 4.5925e-05\n",
      "Epoch 177/300\n",
      "12707/12707 [==============================] - 4s 284us/step - loss: 4.7092e-05\n",
      "Epoch 178/300\n",
      "12707/12707 [==============================] - 4s 290us/step - loss: 4.5673e-05\n",
      "Epoch 179/300\n",
      "12707/12707 [==============================] - 4s 315us/step - loss: 4.4881e-05\n",
      "Epoch 180/300\n",
      "12707/12707 [==============================] - 4s 313us/step - loss: 4.5261e-05\n",
      "Epoch 181/300\n",
      "12707/12707 [==============================] - 3s 271us/step - loss: 4.5327e-05\n",
      "Epoch 182/300\n",
      "12707/12707 [==============================] - 3s 254us/step - loss: 4.5159e-05\n",
      "Epoch 183/300\n",
      "12707/12707 [==============================] - 3s 259us/step - loss: 4.5640e-05\n",
      "Epoch 184/300\n",
      "12707/12707 [==============================] - 3s 249us/step - loss: 4.5348e-05\n",
      "Epoch 185/300\n",
      "12707/12707 [==============================] - 3s 251us/step - loss: 4.4387e-05\n",
      "Epoch 186/300\n",
      "12707/12707 [==============================] - 3s 254us/step - loss: 4.4923e-05\n",
      "Epoch 187/300\n",
      "12707/12707 [==============================] - 3s 251us/step - loss: 4.5017e-05\n",
      "Epoch 188/300\n",
      "12707/12707 [==============================] - 4s 289us/step - loss: 4.4326e-05\n",
      "Epoch 189/300\n",
      "12707/12707 [==============================] - 4s 343us/step - loss: 4.5450e-05\n",
      "Epoch 190/300\n",
      "12707/12707 [==============================] - 4s 333us/step - loss: 4.3778e-05\n",
      "Epoch 191/300\n",
      "12707/12707 [==============================] - ETA: 0s - loss: 4.3975e-0 - 4s 303us/step - loss: 4.4430e-05\n",
      "Epoch 192/300\n",
      "12707/12707 [==============================] - 3s 257us/step - loss: 4.4640e-05\n",
      "Epoch 193/300\n",
      "12707/12707 [==============================] - 3s 246us/step - loss: 4.4203e-05\n",
      "Epoch 194/300\n",
      "12707/12707 [==============================] - 3s 251us/step - loss: 4.4043e-05\n",
      "Epoch 195/300\n",
      "12707/12707 [==============================] - 4s 277us/step - loss: 4.4225e-05 0s - loss: 4.509\n",
      "Epoch 196/300\n",
      "12707/12707 [==============================] - 3s 248us/step - loss: 4.3488e-05\n",
      "Epoch 197/300\n",
      "12707/12707 [==============================] - 3s 256us/step - loss: 4.4463e-05\n",
      "Epoch 198/300\n",
      "12707/12707 [==============================] - 3s 246us/step - loss: 4.4562e-05\n",
      "Epoch 199/300\n",
      "12707/12707 [==============================] - 3s 246us/step - loss: 4.3468e-05\n",
      "Epoch 200/300\n",
      "12707/12707 [==============================] - 3s 247us/step - loss: 4.4946e-05\n",
      "Epoch 201/300\n",
      "12707/12707 [==============================] - 3s 246us/step - loss: 4.3391e-05\n",
      "Epoch 202/300\n",
      "12707/12707 [==============================] - 3s 256us/step - loss: 4.4624e-05\n",
      "Epoch 203/300\n",
      "12707/12707 [==============================] - 3s 256us/step - loss: 4.3483e-05\n",
      "Epoch 204/300\n",
      "12707/12707 [==============================] - ETA: 0s - loss: 4.3619e-0 - 3s 247us/step - loss: 4.3396e-05\n",
      "Epoch 205/300\n",
      "12707/12707 [==============================] - 3s 271us/step - loss: 4.2217e-05\n",
      "Epoch 206/300\n",
      "12707/12707 [==============================] - 3s 249us/step - loss: 4.4690e-05\n",
      "Epoch 207/300\n",
      "12707/12707 [==============================] - 3s 256us/step - loss: 4.3170e-05\n",
      "Epoch 208/300\n",
      "12707/12707 [==============================] - 3s 248us/step - loss: 4.3090e-05\n",
      "Epoch 209/300\n",
      "12707/12707 [==============================] - 3s 250us/step - loss: 4.2698e-05\n",
      "Epoch 210/300\n",
      "12707/12707 [==============================] - 3s 246us/step - loss: 4.2280e-05\n",
      "Epoch 211/300\n",
      "12707/12707 [==============================] - 3s 245us/step - loss: 4.2149e-05\n",
      "Epoch 212/300\n",
      "12707/12707 [==============================] - 3s 258us/step - loss: 4.2076e-05\n",
      "Epoch 213/300\n",
      "12707/12707 [==============================] - 3s 245us/step - loss: 4.1513e-05\n",
      "Epoch 214/300\n",
      "12707/12707 [==============================] - 3s 245us/step - loss: 4.1449e-05\n",
      "Epoch 215/300\n",
      "12707/12707 [==============================] - 3s 246us/step - loss: 4.4048e-05\n",
      "Epoch 216/300\n",
      "12707/12707 [==============================] - 3s 252us/step - loss: 4.3730e-05\n",
      "Epoch 217/300\n",
      "12707/12707 [==============================] - 3s 256us/step - loss: 4.2289e-05\n",
      "Epoch 218/300\n",
      "12707/12707 [==============================] - 3s 245us/step - loss: 4.2337e-05\n",
      "Epoch 219/300\n",
      "12707/12707 [==============================] - 3s 259us/step - loss: 4.0756e-05\n",
      "Epoch 220/300\n",
      "12707/12707 [==============================] - 3s 253us/step - loss: 4.2998e-05\n",
      "Epoch 221/300\n",
      "12707/12707 [==============================] - 3s 251us/step - loss: 4.1801e-05\n",
      "Epoch 222/300\n",
      "12707/12707 [==============================] - 3s 262us/step - loss: 4.2051e-05\n",
      "Epoch 223/300\n",
      "12707/12707 [==============================] - 3s 262us/step - loss: 4.2793e-05\n",
      "Epoch 224/300\n",
      "12707/12707 [==============================] - 4s 310us/step - loss: 4.1844e-05\n",
      "Epoch 225/300\n",
      "12707/12707 [==============================] - 5s 405us/step - loss: 4.1650e-05\n",
      "Epoch 226/300\n",
      "12707/12707 [==============================] - ETA: 0s - loss: 4.0323e-0 - 5s 357us/step - loss: 4.0208e-05\n",
      "Epoch 227/300\n",
      "12707/12707 [==============================] - 4s 335us/step - loss: 4.0523e-05\n",
      "Epoch 228/300\n",
      "12707/12707 [==============================] - 4s 330us/step - loss: 4.2249e-05\n",
      "Epoch 229/300\n",
      "12707/12707 [==============================] - 4s 342us/step - loss: 4.1061e-05 0s - los\n",
      "Epoch 230/300\n",
      "12707/12707 [==============================] - 4s 337us/step - loss: 4.0502e-05\n",
      "Epoch 231/300\n",
      "12707/12707 [==============================] - 4s 341us/step - loss: 4.0432e-05\n",
      "Epoch 232/300\n",
      "12707/12707 [==============================] - 4s 328us/step - loss: 3.9586e-05\n",
      "Epoch 233/300\n",
      "12707/12707 [==============================] - 4s 340us/step - loss: 4.1441e-05\n",
      "Epoch 234/300\n",
      "12707/12707 [==============================] - 4s 335us/step - loss: 4.1622e-05\n",
      "Epoch 235/300\n",
      "12707/12707 [==============================] - 5s 356us/step - loss: 3.9624e-05\n",
      "Epoch 236/300\n",
      "12707/12707 [==============================] - 4s 334us/step - loss: 4.0494e-05\n",
      "Epoch 237/300\n",
      "12707/12707 [==============================] - 5s 363us/step - loss: 4.0614e-05\n",
      "Epoch 238/300\n",
      "12707/12707 [==============================] - 4s 339us/step - loss: 4.0112e-05\n",
      "Epoch 239/300\n",
      "12707/12707 [==============================] - 4s 345us/step - loss: 4.1396e-05\n",
      "Epoch 240/300\n",
      "12707/12707 [==============================] - 4s 335us/step - loss: 4.0534e-05\n",
      "Epoch 241/300\n",
      "12707/12707 [==============================] - 4s 349us/step - loss: 4.0251e-05\n",
      "Epoch 242/300\n",
      "12707/12707 [==============================] - 5s 355us/step - loss: 4.1171e-05\n",
      "Epoch 00242: early stopping\n",
      "##########################  Scores of Train Data  ##########################\n",
      "Train set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: 0.003\n",
      "Train set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: 0.005\n",
      "Train set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: 0.981\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Scores of Test1 Data  ##########################\n",
      "Test1 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: 0.004\n",
      "Test1 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: 0.009\n",
      "Test1 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: 0.948\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Scores of Test2 Data  ##########################\n",
      "Test2 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: 0.037\n",
      "Test2 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: 0.082\n",
      "Test2 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: -7.292\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Details  ##########################\n",
      "957.48s elapsed during modeling\n"
     ]
    }
   ],
   "source": [
    "# Early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=10, verbose=1)\n",
    "\n",
    "\n",
    "# Model\n",
    "\n",
    "#input_dim = 2048\n",
    "#model = KerasRegressor(build_fn=BuildModel(input_dim = 2048), nb_epoch=100, batch_size=3)\n",
    "model = KerasRegressor(build_fn=create_model, batch_size=16, epochs=300, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# Training\n",
    "#np.random.seed(123)\n",
    "modeling(train_encoded=train_encoded, test1_encoded=test1_encoded, test2_encoded=test2_encoded, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem is we optimized for after feature selection. Probably because of the momentum.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "The problem is we optimized for after feature selection.\n",
    "\n",
    "\n",
    "Epoch 242/300\n",
    "12707/12707 [==============================] - 5s 355us/step - loss: 4.1171e-05\n",
    "Epoch 00242: early stopping\n",
    "##########################  Scores of Train Data  ##########################\n",
    "Train set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: 0.003\n",
    "Train set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: 0.005\n",
    "Train set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: 0.981\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Scores of Test1 Data  ##########################\n",
    "Test1 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: 0.004\n",
    "Test1 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: 0.009\n",
    "Test1 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: 0.948\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Scores of Test2 Data  ##########################\n",
    "Test2 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: 0.037\n",
    "Test2 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: 0.082\n",
    "Test2 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: -7.292\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Details  ##########################\n",
    "957.48s elapsed during modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-  Best for without FS ---------------   : 0.956155 using {'activation': 'sigmoid', 'batch_size': 16, 'dropout_rate': 0.1, 'input_dim': 2048, 'learn_rate': 0.05, 'momentum': 0, 'optimizer': 'RMSprop'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "# Function to create model, required for KerasClassifier\n",
    "\n",
    "\n",
    "def create_model(optimizer='RMSprop', learn_rate=0.05, momentum=0, activation='sigmoid', dropout_rate=0.1):\n",
    "    \n",
    "    keras_model = Sequential()\n",
    "    keras_model.add(Dense(128, input_dim=train_encoded.shape[1], activation=activation))\n",
    "    keras_model.add(Dropout(dropout_rate))\n",
    "    keras_model.add(Dense(32, activation=activation)) \n",
    "    keras_model.add(Dropout(dropout_rate))\n",
    "    keras_model.add(Dense(8,activation=activation)) \n",
    "    keras_model.add(Dropout(dropout_rate))\n",
    "    keras_model.add(Dense(1,activation='linear'))\n",
    "    keras_model.summary()\n",
    "    # Compile model\n",
    "    keras_model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "    return keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 266,673\n",
      "Trainable params: 266,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/300\n",
      "12707/12707 [==============================] - 4s 352us/step - loss: 0.0044\n",
      "Epoch 2/300\n",
      "12707/12707 [==============================] - 5s 355us/step - loss: 2.6299e-04\n",
      "Epoch 3/300\n",
      "12707/12707 [==============================] - 4s 328us/step - loss: 1.9272e-04\n",
      "Epoch 4/300\n",
      "12707/12707 [==============================] - 4s 352us/step - loss: 1.7540e-04\n",
      "Epoch 5/300\n",
      "12707/12707 [==============================] - 4s 348us/step - loss: 1.5794e-04\n",
      "Epoch 6/300\n",
      "12707/12707 [==============================] - 5s 362us/step - loss: 1.4884e-04\n",
      "Epoch 7/300\n",
      "12707/12707 [==============================] - 5s 365us/step - loss: 1.4977e-04\n",
      "Epoch 8/300\n",
      "12707/12707 [==============================] - 4s 305us/step - loss: 1.4247e-04\n",
      "Epoch 9/300\n",
      "12707/12707 [==============================] - 3s 265us/step - loss: 1.3972e-04\n",
      "Epoch 10/300\n",
      "12707/12707 [==============================] - 3s 275us/step - loss: 1.3579e-04\n",
      "Epoch 11/300\n",
      "12707/12707 [==============================] - 3s 261us/step - loss: 1.4071e-04\n",
      "Epoch 12/300\n",
      "12707/12707 [==============================] - 4s 322us/step - loss: 1.3269e-04\n",
      "Epoch 13/300\n",
      "12707/12707 [==============================] - 5s 430us/step - loss: 1.3540e-04\n",
      "Epoch 14/300\n",
      "12707/12707 [==============================] - 4s 310us/step - loss: 1.3208e-04\n",
      "Epoch 15/300\n",
      "12707/12707 [==============================] - 4s 290us/step - loss: 1.3484e-04\n",
      "Epoch 16/300\n",
      "12707/12707 [==============================] - 4s 324us/step - loss: 1.3439e-04\n",
      "Epoch 17/300\n",
      "12707/12707 [==============================] - 4s 318us/step - loss: 1.3233e-04\n",
      "Epoch 18/300\n",
      "12707/12707 [==============================] - 4s 289us/step - loss: 1.2578e-04\n",
      "Epoch 19/300\n",
      "12707/12707 [==============================] - 4s 297us/step - loss: 1.2923e-04\n",
      "Epoch 20/300\n",
      "12707/12707 [==============================] - 4s 295us/step - loss: 1.2878e-04\n",
      "Epoch 21/300\n",
      "12707/12707 [==============================] - 3s 275us/step - loss: 1.2780e-04\n",
      "Epoch 22/300\n",
      "12707/12707 [==============================] - 4s 300us/step - loss: 1.2642e-04\n",
      "Epoch 23/300\n",
      "12707/12707 [==============================] - 4s 277us/step - loss: 1.2615e-04\n",
      "Epoch 24/300\n",
      "12707/12707 [==============================] - 4s 297us/step - loss: 1.2405e-04\n",
      "Epoch 25/300\n",
      "12707/12707 [==============================] - 4s 287us/step - loss: 1.2369e-04\n",
      "Epoch 26/300\n",
      "12707/12707 [==============================] - 4s 277us/step - loss: 1.2006e-04\n",
      "Epoch 27/300\n",
      "12707/12707 [==============================] - 3s 268us/step - loss: 1.2375e-04\n",
      "Epoch 28/300\n",
      "12707/12707 [==============================] - 3s 270us/step - loss: 1.2371e-04 0s - los\n",
      "Epoch 29/300\n",
      "12707/12707 [==============================] - 3s 262us/step - loss: 1.2413e-04\n",
      "Epoch 30/300\n",
      "12707/12707 [==============================] - 3s 272us/step - loss: 1.2288e-04\n",
      "Epoch 31/300\n",
      "12707/12707 [==============================] - 3s 267us/step - loss: 1.2591e-04\n",
      "Epoch 32/300\n",
      "12707/12707 [==============================] - 4s 276us/step - loss: 1.1811e-04\n",
      "Epoch 33/300\n",
      "12707/12707 [==============================] - 4s 283us/step - loss: 1.1862e-04\n",
      "Epoch 34/300\n",
      "12707/12707 [==============================] - 3s 273us/step - loss: 1.1902e-04\n",
      "Epoch 35/300\n",
      "12707/12707 [==============================] - 4s 277us/step - loss: 1.1834e-04\n",
      "Epoch 36/300\n",
      "12707/12707 [==============================] - 3s 269us/step - loss: 1.1918e-04 0s - loss: 1\n",
      "Epoch 37/300\n",
      "12707/12707 [==============================] - 3s 254us/step - loss: 1.2122e-04\n",
      "Epoch 38/300\n",
      "12707/12707 [==============================] - 3s 259us/step - loss: 1.2015e-04\n",
      "Epoch 39/300\n",
      "12707/12707 [==============================] - 3s 262us/step - loss: 1.1744e-04\n",
      "Epoch 40/300\n",
      "12707/12707 [==============================] - 3s 265us/step - loss: 1.1796e-04\n",
      "Epoch 41/300\n",
      "12707/12707 [==============================] - 3s 265us/step - loss: 1.2020e-04\n",
      "Epoch 42/300\n",
      "12707/12707 [==============================] - 3s 267us/step - loss: 1.1837e-04\n",
      "Epoch 43/300\n",
      "12707/12707 [==============================] - 4s 278us/step - loss: 1.1611e-04\n",
      "Epoch 44/300\n",
      "12707/12707 [==============================] - 3s 259us/step - loss: 1.1978e-04\n",
      "Epoch 45/300\n",
      "12707/12707 [==============================] - 3s 265us/step - loss: 1.2207e-04\n",
      "Epoch 46/300\n",
      "12707/12707 [==============================] - 3s 260us/step - loss: 1.1450e-04\n",
      "Epoch 47/300\n",
      "12707/12707 [==============================] - 3s 271us/step - loss: 1.1273e-04\n",
      "Epoch 48/300\n",
      "12707/12707 [==============================] - 3s 259us/step - loss: 1.1712e-04\n",
      "Epoch 49/300\n",
      "12707/12707 [==============================] - 4s 291us/step - loss: 1.1496e-04\n",
      "Epoch 50/300\n",
      "12707/12707 [==============================] - 4s 286us/step - loss: 1.1598e-04\n",
      "Epoch 51/300\n",
      "12707/12707 [==============================] - 4s 297us/step - loss: 1.1617e-04\n",
      "Epoch 52/300\n",
      "12707/12707 [==============================] - 4s 290us/step - loss: 1.1747e-04\n",
      "Epoch 53/300\n",
      "12707/12707 [==============================] - 4s 353us/step - loss: 1.1524e-04\n",
      "Epoch 54/300\n",
      "12707/12707 [==============================] - 4s 327us/step - loss: 1.1082e-04\n",
      "Epoch 55/300\n",
      "12707/12707 [==============================] - 4s 340us/step - loss: 1.2018e-04\n",
      "Epoch 56/300\n",
      "12707/12707 [==============================] - 4s 343us/step - loss: 1.1612e-04\n",
      "Epoch 57/300\n",
      "12707/12707 [==============================] - 4s 332us/step - loss: 1.1659e-04\n",
      "Epoch 58/300\n",
      "12707/12707 [==============================] - 4s 331us/step - loss: 1.1895e-04\n",
      "Epoch 59/300\n",
      "12707/12707 [==============================] - 4s 348us/step - loss: 1.1641e-04\n",
      "Epoch 60/300\n",
      "12707/12707 [==============================] - 4s 334us/step - loss: 1.1253e-04\n",
      "Epoch 61/300\n",
      "12707/12707 [==============================] - 4s 342us/step - loss: 1.1355e-04\n",
      "Epoch 62/300\n",
      "12707/12707 [==============================] - 4s 335us/step - loss: 1.1174e-04\n",
      "Epoch 63/300\n",
      "12707/12707 [==============================] - 4s 350us/step - loss: 1.1454e-04\n",
      "Epoch 64/300\n",
      "12707/12707 [==============================] - 4s 336us/step - loss: 1.1113e-04\n",
      "Epoch 00064: early stopping\n",
      "##########################  Scores of Train Data  ##########################\n",
      "Train set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.003\n",
      "Train set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.007\n",
      "Train set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.966\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Scores of Test1 Data  ##########################\n",
      "Test1 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.004\n",
      "Test1 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.008\n",
      "Test1 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.961\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Scores of Test2 Data  ##########################\n",
      "Test2 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.008\n",
      "Test2 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.009\n",
      "Test2 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.893\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Details  ##########################\n",
      "246.22s elapsed during modeling\n"
     ]
    }
   ],
   "source": [
    "# Early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=10, verbose=1)\n",
    "\n",
    "\n",
    "# Model\n",
    "\n",
    "#input_dim = 2048\n",
    "model = KerasRegressor(build_fn=create_model, batch_size=16, epochs=300, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# Training\n",
    "#np.random.seed(123)\n",
    "modeling(train_encoded=train_encoded, test1_encoded=test1_encoded, test2_encoded=test2_encoded, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Epoch 64/300\n",
    "12707/12707 [==============================] - 4s 336us/step - loss: 1.1113e-04\n",
    "Epoch 00064: early stopping\n",
    "##########################  Scores of Train Data  ##########################\n",
    "Train set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.003\n",
    "Train set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.007\n",
    "Train set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.966\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Scores of Test1 Data  ##########################\n",
    "Test1 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.004\n",
    "Test1 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.008\n",
    "Test1 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.961\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Scores of Test2 Data  ##########################\n",
    "Test2 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.008\n",
    "Test2 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.009\n",
    "Test2 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.893\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Details  ##########################\n",
    "246.22s elapsed during modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------- FINAL MODEL ----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After decreasing patience from 10 to 5..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "# Function to create model, required for KerasClassifier\n",
    "\n",
    "\n",
    "def create_model(optimizer='RMSprop', learn_rate=0.05, momentum=0, activation='sigmoid', dropout_rate=0.1):\n",
    "    \n",
    "    keras_model = Sequential()\n",
    "    keras_model.add(Dense(128, input_dim=train_encoded.shape[1], activation=activation))\n",
    "    keras_model.add(Dropout(dropout_rate))\n",
    "    keras_model.add(Dense(32, activation=activation)) \n",
    "    keras_model.add(Dropout(dropout_rate))\n",
    "    keras_model.add(Dense(8,activation=activation)) \n",
    "    keras_model.add(Dropout(dropout_rate))\n",
    "    keras_model.add(Dense(1,activation='linear'))\n",
    "    keras_model.summary()\n",
    "    # Compile model\n",
    "    keras_model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "    return keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 266,673\n",
      "Trainable params: 266,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/300\n",
      "12707/12707 [==============================] - 5s 414us/step - loss: 0.0044\n",
      "Epoch 2/300\n",
      "12707/12707 [==============================] - 4s 332us/step - loss: 2.6299e-04\n",
      "Epoch 3/300\n",
      "12707/12707 [==============================] - 4s 349us/step - loss: 1.9272e-04\n",
      "Epoch 4/300\n",
      "12707/12707 [==============================] - 4s 337us/step - loss: 1.7540e-04\n",
      "Epoch 5/300\n",
      "12707/12707 [==============================] - 4s 314us/step - loss: 1.5794e-04\n",
      "Epoch 6/300\n",
      "12707/12707 [==============================] - 4s 296us/step - loss: 1.4884e-04 0s \n",
      "Epoch 7/300\n",
      "12707/12707 [==============================] - 4s 306us/step - loss: 1.4977e-04\n",
      "Epoch 8/300\n",
      "12707/12707 [==============================] - 4s 321us/step - loss: 1.4247e-04\n",
      "Epoch 9/300\n",
      "12707/12707 [==============================] - 4s 300us/step - loss: 1.3972e-04\n",
      "Epoch 10/300\n",
      "12707/12707 [==============================] - 4s 302us/step - loss: 1.3579e-04\n",
      "Epoch 11/300\n",
      "12707/12707 [==============================] - 4s 321us/step - loss: 1.4071e-04 0s - loss: 1.394\n",
      "Epoch 12/300\n",
      "12707/12707 [==============================] - 4s 342us/step - loss: 1.3269e-04\n",
      "Epoch 13/300\n",
      "12707/12707 [==============================] - 4s 313us/step - loss: 1.3540e-04\n",
      "Epoch 14/300\n",
      "12707/12707 [==============================] - 4s 296us/step - loss: 1.3208e-04\n",
      "Epoch 15/300\n",
      "12707/12707 [==============================] - 4s 294us/step - loss: 1.3484e-04\n",
      "Epoch 16/300\n",
      "12707/12707 [==============================] - 4s 291us/step - loss: 1.3439e-04\n",
      "Epoch 17/300\n",
      "12707/12707 [==============================] - 4s 334us/step - loss: 1.3233e-04\n",
      "Epoch 18/300\n",
      "12707/12707 [==============================] - 4s 312us/step - loss: 1.2578e-04\n",
      "Epoch 19/300\n",
      "12707/12707 [==============================] - 4s 309us/step - loss: 1.2923e-04\n",
      "Epoch 20/300\n",
      "12707/12707 [==============================] - 4s 279us/step - loss: 1.2878e-04\n",
      "Epoch 21/300\n",
      "12707/12707 [==============================] - 4s 324us/step - loss: 1.2780e-04\n",
      "Epoch 22/300\n",
      "12707/12707 [==============================] - 4s 311us/step - loss: 1.2642e-04\n",
      "Epoch 23/300\n",
      "12707/12707 [==============================] - 4s 297us/step - loss: 1.2615e-04\n",
      "Epoch 00023: early stopping\n",
      "##########################  Scores of Train Data  ##########################\n",
      "Train set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001B5E3CF5BC8>: 0.004\n",
      "Train set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001B5E3CF5BC8>: 0.008\n",
      "Train set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001B5E3CF5BC8>: 0.959\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Scores of Test1 Data  ##########################\n",
      "Test1 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001B5E3CF5BC8>: 0.004\n",
      "Test1 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001B5E3CF5BC8>: 0.008\n",
      "Test1 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001B5E3CF5BC8>: 0.962\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Scores of Test2 Data  ##########################\n",
      "Test2 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001B5E3CF5BC8>: 0.005\n",
      "Test2 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001B5E3CF5BC8>: 0.006\n",
      "Test2 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001B5E3CF5BC8>: 0.952\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Details  ##########################\n",
      "95.05s elapsed during modeling\n"
     ]
    }
   ],
   "source": [
    "# Early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5, verbose=1)\n",
    "\n",
    "\n",
    "# Model\n",
    "\n",
    "#input_dim = 2048\n",
    "model = KerasRegressor(build_fn=create_model, batch_size=16, epochs=300, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# Training\n",
    "#np.random.seed(123)\n",
    "modeling(train_encoded=train_encoded, test1_encoded=test1_encoded, test2_encoded=test2_encoded, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---------------------------- Reproducible (Checked=4) ----------------------------\n",
    "\n",
    "Epoch 22/300\n",
    "12707/12707 [==============================] - 5s 373us/step - loss: 1.2642e-04\n",
    "Epoch 23/300\n",
    "12707/12707 [==============================] - 4s 346us/step - loss: 1.2615e-04\n",
    "Epoch 00023: early stopping\n",
    "##########################  Scores of Train Data  ##########################\n",
    "Train set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000023382BB9408>: 0.004\n",
    "Train set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000023382BB9408>: 0.008\n",
    "Train set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000023382BB9408>: 0.959\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Scores of Test1 Data  ##########################\n",
    "Test1 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000023382BB9408>: 0.004\n",
    "Test1 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000023382BB9408>: 0.008\n",
    "Test1 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000023382BB9408>: 0.962\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Scores of Test2 Data  ##########################\n",
    "Test2 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000023382BB9408>: 0.005\n",
    "Test2 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000023382BB9408>: 0.006\n",
    "Test2 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000023382BB9408>: 0.952\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Details  ##########################\n",
    "110.66s elapsed during modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Test 1 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reaction_id</th>\n",
       "      <th>data_package_id</th>\n",
       "      <th>bond_type</th>\n",
       "      <th>functional_group_stoichiometry</th>\n",
       "      <th>reactant_smiles</th>\n",
       "      <th>product_smiles</th>\n",
       "      <th>reactant_inchiKey</th>\n",
       "      <th>product_inchiKey</th>\n",
       "      <th>reactant_solubility</th>\n",
       "      <th>product_solubility</th>\n",
       "      <th>...</th>\n",
       "      <th>product_single_point_job_id</th>\n",
       "      <th>reactant_optimization_job_id</th>\n",
       "      <th>product_optimization_job_id</th>\n",
       "      <th>UMAP-1</th>\n",
       "      <th>UMAP-2</th>\n",
       "      <th>data_type</th>\n",
       "      <th>reactantUFF</th>\n",
       "      <th>reactantMMFF</th>\n",
       "      <th>productUFF</th>\n",
       "      <th>productMMFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>OH</td>\n",
       "      <td>COOH</td>\n",
       "      <td>O=C1CC(=O)C(C(=O)O)=C1C(=O)O</td>\n",
       "      <td>C1C(O)=C(C(=O)O)C(=C1O)C(=O)O</td>\n",
       "      <td>QLGSJNWSAMBDMI-UHFFFAOYSA-N</td>\n",
       "      <td>AEVQXUUICHCAGT-UHFFFAOYSA-N</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.867</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>13.362195</td>\n",
       "      <td>3.405288</td>\n",
       "      <td>1</td>\n",
       "      <td>33.280029</td>\n",
       "      <td>-113.415199</td>\n",
       "      <td>37.053325</td>\n",
       "      <td>-2.716193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>OH</td>\n",
       "      <td>F</td>\n",
       "      <td>O=C1CC(=O)C=C1F</td>\n",
       "      <td>C1C(O)=C(F)C=C1O</td>\n",
       "      <td>XVCHEZRSXGJYDT-UHFFFAOYSA-N</td>\n",
       "      <td>LLYKNQJBRVSOKM-UHFFFAOYSA-N</td>\n",
       "      <td>-0.524</td>\n",
       "      <td>-0.499</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>14.856011</td>\n",
       "      <td>2.316219</td>\n",
       "      <td>1</td>\n",
       "      <td>23.112465</td>\n",
       "      <td>-12.882731</td>\n",
       "      <td>24.103198</td>\n",
       "      <td>34.474933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   reaction_id  data_package_id bond_type functional_group_stoichiometry  \\\n",
       "2            3                1        OH                           COOH   \n",
       "3            4                1        OH                              F   \n",
       "\n",
       "                reactant_smiles                 product_smiles  \\\n",
       "2  O=C1CC(=O)C(C(=O)O)=C1C(=O)O  C1C(O)=C(C(=O)O)C(=C1O)C(=O)O   \n",
       "3               O=C1CC(=O)C=C1F               C1C(O)=C(F)C=C1O   \n",
       "\n",
       "             reactant_inchiKey             product_inchiKey  \\\n",
       "2  QLGSJNWSAMBDMI-UHFFFAOYSA-N  AEVQXUUICHCAGT-UHFFFAOYSA-N   \n",
       "3  XVCHEZRSXGJYDT-UHFFFAOYSA-N  LLYKNQJBRVSOKM-UHFFFAOYSA-N   \n",
       "\n",
       "   reactant_solubility  product_solubility  ...  product_single_point_job_id  \\\n",
       "2               -0.966              -0.867  ...                         26.0   \n",
       "3               -0.524              -0.499  ...                         34.0   \n",
       "\n",
       "   reactant_optimization_job_id  product_optimization_job_id     UMAP-1  \\\n",
       "2                          19.0                         25.0  13.362195   \n",
       "3                          21.0                         33.0  14.856011   \n",
       "\n",
       "     UMAP-2  data_type  reactantUFF  reactantMMFF  productUFF  productMMFF  \n",
       "2  3.405288          1    33.280029   -113.415199   37.053325    -2.716193  \n",
       "3  2.316219          1    23.112465    -12.882731   24.103198    34.474933  \n",
       "\n",
       "[2 rows x 46 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reaction_id</th>\n",
       "      <th>reactant_smiles</th>\n",
       "      <th>reaction_energy</th>\n",
       "      <th>pred_test1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>O=C1CC(=O)C(C(=O)O)=C1C(=O)O</td>\n",
       "      <td>-0.06394</td>\n",
       "      <td>-0.046921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>O=C1CC(=O)C=C1F</td>\n",
       "      <td>-0.01642</td>\n",
       "      <td>-0.012994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>O=C1NC(=O)C=C1</td>\n",
       "      <td>-0.00731</td>\n",
       "      <td>-0.006922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>O=C1NC(=O)C(F)=C1F</td>\n",
       "      <td>-0.00118</td>\n",
       "      <td>0.014583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>O=C1SC(=O)C(C(=O)O)=C1C(=O)O</td>\n",
       "      <td>-0.06775</td>\n",
       "      <td>-0.057425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15759</th>\n",
       "      <td>15897</td>\n",
       "      <td>O=S(=O)(O)c(c1)cc(S(=O)(=O)O)c(c12)c(O)n(c2O)N...</td>\n",
       "      <td>-0.00215</td>\n",
       "      <td>-0.002250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15762</th>\n",
       "      <td>15900</td>\n",
       "      <td>c1cccc(c12)c(O)n(c2O)N(C3=O)C(=O)c(c34)c(S(=O)...</td>\n",
       "      <td>0.02162</td>\n",
       "      <td>0.004420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15768</th>\n",
       "      <td>15906</td>\n",
       "      <td>O=S(=O)(O)c(c1)c(S(=O)(=O)O)c(S(=O)(=O)O)c(c12...</td>\n",
       "      <td>-0.01803</td>\n",
       "      <td>-0.017114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15788</th>\n",
       "      <td>15927</td>\n",
       "      <td>O=S(=O)(O)c1ccc(S(=O)(=O)O)c(c12)c(O)n(c2O)N(C...</td>\n",
       "      <td>-0.03881</td>\n",
       "      <td>-0.014094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15791</th>\n",
       "      <td>15930</td>\n",
       "      <td>O=S(=O)(O)c1c(S(=O)(=O)O)c(S(=O)(=O)O)c(S(=O)(...</td>\n",
       "      <td>0.00826</td>\n",
       "      <td>-0.024482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1607 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       reaction_id                                    reactant_smiles  \\\n",
       "2                3                       O=C1CC(=O)C(C(=O)O)=C1C(=O)O   \n",
       "3                4                                    O=C1CC(=O)C=C1F   \n",
       "13              14                                     O=C1NC(=O)C=C1   \n",
       "14              15                                 O=C1NC(=O)C(F)=C1F   \n",
       "24              25                       O=C1SC(=O)C(C(=O)O)=C1C(=O)O   \n",
       "...            ...                                                ...   \n",
       "15759        15897  O=S(=O)(O)c(c1)cc(S(=O)(=O)O)c(c12)c(O)n(c2O)N...   \n",
       "15762        15900  c1cccc(c12)c(O)n(c2O)N(C3=O)C(=O)c(c34)c(S(=O)...   \n",
       "15768        15906  O=S(=O)(O)c(c1)c(S(=O)(=O)O)c(S(=O)(=O)O)c(c12...   \n",
       "15788        15927  O=S(=O)(O)c1ccc(S(=O)(=O)O)c(c12)c(O)n(c2O)N(C...   \n",
       "15791        15930  O=S(=O)(O)c1c(S(=O)(=O)O)c(S(=O)(=O)O)c(S(=O)(...   \n",
       "\n",
       "       reaction_energy  pred_test1  \n",
       "2             -0.06394   -0.046921  \n",
       "3             -0.01642   -0.012994  \n",
       "13            -0.00731   -0.006922  \n",
       "14            -0.00118    0.014583  \n",
       "24            -0.06775   -0.057425  \n",
       "...                ...         ...  \n",
       "15759         -0.00215   -0.002250  \n",
       "15762          0.02162    0.004420  \n",
       "15768         -0.01803   -0.017114  \n",
       "15788         -0.03881   -0.014094  \n",
       "15791          0.00826   -0.024482  \n",
       "\n",
       "[1607 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test1 = model.predict(test1_encoded.values)\n",
    "keras_result_test1 = test1_data[[\"reaction_id\", \"reactant_smiles\", \"reaction_energy\"]]\n",
    "keras_result_test1[\"pred_test1\"] = pred_test1\n",
    "keras_result_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04692131, -0.01299443, -0.00692186, ..., -0.01711423,\n",
       "       -0.01409437, -0.0244816 ], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the dataframe\n",
    "keras_result_test1.to_csv(r'.\\final_models\\keras_result_test1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Test 2 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reaction_id</th>\n",
       "      <th>data_package_id</th>\n",
       "      <th>bond_type</th>\n",
       "      <th>functional_group_stoichiometry</th>\n",
       "      <th>reactant_smiles</th>\n",
       "      <th>product_smiles</th>\n",
       "      <th>reactant_inchiKey</th>\n",
       "      <th>product_inchiKey</th>\n",
       "      <th>reactant_solubility</th>\n",
       "      <th>product_solubility</th>\n",
       "      <th>...</th>\n",
       "      <th>product_single_point_job_id</th>\n",
       "      <th>reactant_optimization_job_id</th>\n",
       "      <th>product_optimization_job_id</th>\n",
       "      <th>UMAP-1</th>\n",
       "      <th>UMAP-2</th>\n",
       "      <th>data_type</th>\n",
       "      <th>reactantUFF</th>\n",
       "      <th>reactantMMFF</th>\n",
       "      <th>productUFF</th>\n",
       "      <th>productMMFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>769</td>\n",
       "      <td>25</td>\n",
       "      <td>NH</td>\n",
       "      <td>OH</td>\n",
       "      <td>c1cccc(c12)cc(nn2)O</td>\n",
       "      <td>c1cccc(c12)C=C(O)NN2</td>\n",
       "      <td>CXUGAWWYKSOLEL-UHFFFAOYSA-N</td>\n",
       "      <td>BMBWSQWNXPSELG-UHFFFAOYSA-N</td>\n",
       "      <td>-2.080</td>\n",
       "      <td>-2.410</td>\n",
       "      <td>...</td>\n",
       "      <td>2965.0</td>\n",
       "      <td>2369.0</td>\n",
       "      <td>2964.0</td>\n",
       "      <td>21.961576</td>\n",
       "      <td>-2.257458</td>\n",
       "      <td>2</td>\n",
       "      <td>20.955169</td>\n",
       "      <td>18.343820</td>\n",
       "      <td>17.140645</td>\n",
       "      <td>19.530730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>774</td>\n",
       "      <td>25</td>\n",
       "      <td>NH</td>\n",
       "      <td>OH</td>\n",
       "      <td>Oc1cccc(c12)cc(nn2)O</td>\n",
       "      <td>Oc1cccc(c12)C=C(O)NN2</td>\n",
       "      <td>BSAMMELAAJYOKU-UHFFFAOYSA-N</td>\n",
       "      <td>QXPSFNRPQZDOFI-UHFFFAOYSA-N</td>\n",
       "      <td>-2.173</td>\n",
       "      <td>-2.142</td>\n",
       "      <td>...</td>\n",
       "      <td>3339.0</td>\n",
       "      <td>2335.0</td>\n",
       "      <td>3338.0</td>\n",
       "      <td>22.153984</td>\n",
       "      <td>-2.141872</td>\n",
       "      <td>2</td>\n",
       "      <td>22.612127</td>\n",
       "      <td>27.933289</td>\n",
       "      <td>20.633665</td>\n",
       "      <td>23.125357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     reaction_id  data_package_id bond_type functional_group_stoichiometry  \\\n",
       "767          769               25        NH                             OH   \n",
       "772          774               25        NH                             OH   \n",
       "\n",
       "          reactant_smiles         product_smiles            reactant_inchiKey  \\\n",
       "767   c1cccc(c12)cc(nn2)O   c1cccc(c12)C=C(O)NN2  CXUGAWWYKSOLEL-UHFFFAOYSA-N   \n",
       "772  Oc1cccc(c12)cc(nn2)O  Oc1cccc(c12)C=C(O)NN2  BSAMMELAAJYOKU-UHFFFAOYSA-N   \n",
       "\n",
       "                product_inchiKey  reactant_solubility  product_solubility  \\\n",
       "767  BMBWSQWNXPSELG-UHFFFAOYSA-N               -2.080              -2.410   \n",
       "772  QXPSFNRPQZDOFI-UHFFFAOYSA-N               -2.173              -2.142   \n",
       "\n",
       "     ...  product_single_point_job_id  reactant_optimization_job_id  \\\n",
       "767  ...                       2965.0                        2369.0   \n",
       "772  ...                       3339.0                        2335.0   \n",
       "\n",
       "     product_optimization_job_id     UMAP-1    UMAP-2  data_type  reactantUFF  \\\n",
       "767                       2964.0  21.961576 -2.257458          2    20.955169   \n",
       "772                       3338.0  22.153984 -2.141872          2    22.612127   \n",
       "\n",
       "     reactantMMFF  productUFF  productMMFF  \n",
       "767     18.343820   17.140645    19.530730  \n",
       "772     27.933289   20.633665    23.125357  \n",
       "\n",
       "[2 rows x 46 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reaction_id</th>\n",
       "      <th>reactant_smiles</th>\n",
       "      <th>reaction_energy</th>\n",
       "      <th>pred_test2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>769</td>\n",
       "      <td>c1cccc(c12)cc(nn2)O</td>\n",
       "      <td>-0.01916</td>\n",
       "      <td>-0.017922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>774</td>\n",
       "      <td>Oc1cccc(c12)cc(nn2)O</td>\n",
       "      <td>-0.01587</td>\n",
       "      <td>-0.013521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>778</td>\n",
       "      <td>c1c(O)ccc(c12)cc(nn2)O</td>\n",
       "      <td>-0.01793</td>\n",
       "      <td>-0.013437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>781</td>\n",
       "      <td>c1cc(O)cc(c12)cc(nn2)O</td>\n",
       "      <td>-0.01559</td>\n",
       "      <td>-0.013862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>783</td>\n",
       "      <td>c1ccc(O)c(c12)cc(nn2)O</td>\n",
       "      <td>-0.01734</td>\n",
       "      <td>-0.014143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14233</th>\n",
       "      <td>14338</td>\n",
       "      <td>O=C(O)c1cc(C(=O)O)c(C(=O)O)c(c12)S/C(C2=O)=C(C...</td>\n",
       "      <td>-0.06081</td>\n",
       "      <td>-0.050426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14234</th>\n",
       "      <td>14339</td>\n",
       "      <td>O=C(O)c1c(C(=O)O)cc(C(=O)O)c(c12)S/C(C2=O)=C(C...</td>\n",
       "      <td>-0.04998</td>\n",
       "      <td>-0.048198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14235</th>\n",
       "      <td>14340</td>\n",
       "      <td>O=C(O)c1c(C(=O)O)cc(C(=O)O)c(c12)S/C(C2=O)=C(C...</td>\n",
       "      <td>-0.05763</td>\n",
       "      <td>-0.045113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14236</th>\n",
       "      <td>14341</td>\n",
       "      <td>O=C(O)c1c(C(=O)O)c(C(=O)O)cc(c12)S/C(C2=O)=C(C...</td>\n",
       "      <td>-0.05533</td>\n",
       "      <td>-0.042310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14237</th>\n",
       "      <td>14342</td>\n",
       "      <td>O=C(O)c1c(C(=O)O)c(C(=O)O)c(C(=O)O)c(c12)S/C(C...</td>\n",
       "      <td>-0.05424</td>\n",
       "      <td>-0.045324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1480 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       reaction_id                                    reactant_smiles  \\\n",
       "767            769                                c1cccc(c12)cc(nn2)O   \n",
       "772            774                               Oc1cccc(c12)cc(nn2)O   \n",
       "776            778                             c1c(O)ccc(c12)cc(nn2)O   \n",
       "779            781                             c1cc(O)cc(c12)cc(nn2)O   \n",
       "781            783                             c1ccc(O)c(c12)cc(nn2)O   \n",
       "...            ...                                                ...   \n",
       "14233        14338  O=C(O)c1cc(C(=O)O)c(C(=O)O)c(c12)S/C(C2=O)=C(C...   \n",
       "14234        14339  O=C(O)c1c(C(=O)O)cc(C(=O)O)c(c12)S/C(C2=O)=C(C...   \n",
       "14235        14340  O=C(O)c1c(C(=O)O)cc(C(=O)O)c(c12)S/C(C2=O)=C(C...   \n",
       "14236        14341  O=C(O)c1c(C(=O)O)c(C(=O)O)cc(c12)S/C(C2=O)=C(C...   \n",
       "14237        14342  O=C(O)c1c(C(=O)O)c(C(=O)O)c(C(=O)O)c(c12)S/C(C...   \n",
       "\n",
       "       reaction_energy  pred_test2  \n",
       "767           -0.01916   -0.017922  \n",
       "772           -0.01587   -0.013521  \n",
       "776           -0.01793   -0.013437  \n",
       "779           -0.01559   -0.013862  \n",
       "781           -0.01734   -0.014143  \n",
       "...                ...         ...  \n",
       "14233         -0.06081   -0.050426  \n",
       "14234         -0.04998   -0.048198  \n",
       "14235         -0.05763   -0.045113  \n",
       "14236         -0.05533   -0.042310  \n",
       "14237         -0.05424   -0.045324  \n",
       "\n",
       "[1480 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test2 = model.predict(test2_encoded.values)\n",
    "keras_result_test2 = test2_data[[\"reaction_id\", \"reactant_smiles\", \"reaction_energy\"]]\n",
    "keras_result_test2[\"pred_test2\"] = pred_test2\n",
    "keras_result_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01792245, -0.01352063, -0.01343709, ..., -0.04511323,\n",
       "       -0.04231039, -0.04532441], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the dataframe\n",
    "keras_result_test2.to_csv(r'.\\final_models\\keras_result_test2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.wrappers.scikit_learn.KerasRegressor at 0x1b5e3cf5bc8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04692131, -0.01299443, -0.00692186, ..., -0.01711423,\n",
       "       -0.01409437, -0.0244816 ], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test1 = model.predict(test1_encoded.values)\n",
    "pred_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save\n",
    "pickle.dump(model, open(r'.\\final_models\\keras_final_model.txt', \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Saved model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.wrappers.scikit_learn.KerasRegressor at 0x1b59b0eb308>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load\n",
    "keras_final_model = pickle.load(open(r'.\\final_models\\keras_final_model.txt', \"rb\"))\n",
    "keras_final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04692131, -0.01299443, -0.00692186, ..., -0.01711423,\n",
       "       -0.01409437, -0.0244816 ], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_pred_test1 = keras_final_model.predict(test1_encoded.values)\n",
    "s_pred_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After deleting last dropout layer...  DIDN'T WORK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "# Function to create model, required for KerasClassifier\n",
    "\n",
    "\n",
    "def create_model(optimizer='RMSprop', learn_rate=0.05, momentum=0, activation='sigmoid', dropout_rate=0.1):\n",
    "    \n",
    "    keras_model = Sequential()\n",
    "    keras_model.add(Dense(128, input_dim=train_encoded.shape[1], activation=activation))\n",
    "    keras_model.add(Dropout(dropout_rate))\n",
    "    keras_model.add(Dense(32, activation=activation)) \n",
    "    keras_model.add(Dropout(dropout_rate))\n",
    "    keras_model.add(Dense(8,activation=activation)) \n",
    "    keras_model.add(Dense(1,activation='linear'))\n",
    "    keras_model.summary()\n",
    "    # Compile model\n",
    "    keras_model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "    return keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 266,673\n",
      "Trainable params: 266,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/300\n",
      "12707/12707 [==============================] - 4s 341us/step - loss: 0.0058\n",
      "Epoch 2/300\n",
      "12707/12707 [==============================] - 4s 340us/step - loss: 2.7221e-04\n",
      "Epoch 3/300\n",
      "12707/12707 [==============================] - 4s 331us/step - loss: 1.9975e-04\n",
      "Epoch 4/300\n",
      "12707/12707 [==============================] - 4s 329us/step - loss: 1.7347e-04\n",
      "Epoch 5/300\n",
      "12707/12707 [==============================] - 4s 350us/step - loss: 1.6041e-04\n",
      "Epoch 6/300\n",
      "12707/12707 [==============================] - 5s 365us/step - loss: 1.4558e-04\n",
      "Epoch 7/300\n",
      "12707/12707 [==============================] - 4s 338us/step - loss: 1.3794e-04\n",
      "Epoch 8/300\n",
      "12707/12707 [==============================] - 5s 355us/step - loss: 1.3149e-04\n",
      "Epoch 9/300\n",
      "12707/12707 [==============================] - 4s 349us/step - loss: 1.2732e-04\n",
      "Epoch 10/300\n",
      "12707/12707 [==============================] - 5s 356us/step - loss: 1.2281e-04\n",
      "Epoch 11/300\n",
      "12707/12707 [==============================] - 4s 316us/step - loss: 1.2047e-04\n",
      "Epoch 12/300\n",
      "12707/12707 [==============================] - 4s 320us/step - loss: 1.1994e-04\n",
      "Epoch 13/300\n",
      "12707/12707 [==============================] - 4s 325us/step - loss: 1.1542e-04\n",
      "Epoch 14/300\n",
      "12707/12707 [==============================] - 4s 315us/step - loss: 1.1151e-04\n",
      "Epoch 15/300\n",
      "12707/12707 [==============================] - 4s 316us/step - loss: 1.1175e-04\n",
      "Epoch 16/300\n",
      "12707/12707 [==============================] - 4s 320us/step - loss: 1.0939e-04\n",
      "Epoch 17/300\n",
      "12707/12707 [==============================] - 4s 329us/step - loss: 1.0905e-04\n",
      "Epoch 18/300\n",
      "12707/12707 [==============================] - 4s 313us/step - loss: 1.0562e-04\n",
      "Epoch 19/300\n",
      "12707/12707 [==============================] - 4s 334us/step - loss: 1.0485e-04\n",
      "Epoch 20/300\n",
      "12707/12707 [==============================] - 5s 360us/step - loss: 1.0607e-04\n",
      "Epoch 21/300\n",
      "12707/12707 [==============================] - 5s 366us/step - loss: 1.0202e-04\n",
      "Epoch 22/300\n",
      "12707/12707 [==============================] - 4s 332us/step - loss: 1.0312e-04\n",
      "Epoch 23/300\n",
      "12707/12707 [==============================] - 5s 359us/step - loss: 9.9797e-05\n",
      "Epoch 24/300\n",
      "12707/12707 [==============================] - 4s 347us/step - loss: 9.9648e-05\n",
      "Epoch 25/300\n",
      "12707/12707 [==============================] - 4s 336us/step - loss: 9.8592e-05\n",
      "Epoch 26/300\n",
      "12707/12707 [==============================] - 4s 335us/step - loss: 1.0029e-04\n",
      "Epoch 27/300\n",
      "12707/12707 [==============================] - 4s 321us/step - loss: 9.8575e-05\n",
      "Epoch 28/300\n",
      "12707/12707 [==============================] - 4s 332us/step - loss: 9.5276e-05\n",
      "Epoch 29/300\n",
      "12707/12707 [==============================] - 4s 324us/step - loss: 9.6416e-05\n",
      "Epoch 30/300\n",
      "12707/12707 [==============================] - 4s 323us/step - loss: 9.4941e-05\n",
      "Epoch 31/300\n",
      "12707/12707 [==============================] - 4s 324us/step - loss: 9.3318e-05\n",
      "Epoch 32/300\n",
      "12707/12707 [==============================] - 5s 370us/step - loss: 9.3563e-05\n",
      "Epoch 33/300\n",
      "12707/12707 [==============================] - 4s 325us/step - loss: 9.4691e-05\n",
      "Epoch 34/300\n",
      "12707/12707 [==============================] - 4s 331us/step - loss: 9.1650e-05 0s - loss: 8.6\n",
      "Epoch 35/300\n",
      "12707/12707 [==============================] - 4s 319us/step - loss: 9.1073e-05\n",
      "Epoch 36/300\n",
      "12707/12707 [==============================] - 4s 345us/step - loss: 9.2056e-05\n",
      "Epoch 37/300\n",
      "12707/12707 [==============================] - 4s 349us/step - loss: 9.1848e-05\n",
      "Epoch 38/300\n",
      "12707/12707 [==============================] - 4s 346us/step - loss: 9.0103e-05\n",
      "Epoch 39/300\n",
      "12707/12707 [==============================] - 4s 338us/step - loss: 8.9865e-05\n",
      "Epoch 40/300\n",
      "12707/12707 [==============================] - 5s 368us/step - loss: 9.0332e-05\n",
      "Epoch 41/300\n",
      "12707/12707 [==============================] - 4s 350us/step - loss: 8.9124e-05\n",
      "Epoch 42/300\n",
      "12707/12707 [==============================] - 5s 362us/step - loss: 8.9522e-05\n",
      "Epoch 43/300\n",
      "12707/12707 [==============================] - 4s 347us/step - loss: 8.8348e-05\n",
      "Epoch 44/300\n",
      "12707/12707 [==============================] - 4s 343us/step - loss: 8.9481e-05\n",
      "Epoch 45/300\n",
      "12707/12707 [==============================] - 4s 332us/step - loss: 8.7332e-05\n",
      "Epoch 46/300\n",
      "12707/12707 [==============================] - 4s 314us/step - loss: 8.6612e-05\n",
      "Epoch 47/300\n",
      "12707/12707 [==============================] - 4s 336us/step - loss: 8.7455e-05\n",
      "Epoch 48/300\n",
      "12707/12707 [==============================] - 4s 317us/step - loss: 8.5881e-05\n",
      "Epoch 49/300\n",
      "12707/12707 [==============================] - 4s 317us/step - loss: 8.7344e-05\n",
      "Epoch 50/300\n",
      "12707/12707 [==============================] - 4s 324us/step - loss: 8.6699e-05\n",
      "Epoch 51/300\n",
      "12707/12707 [==============================] - 4s 334us/step - loss: 8.5993e-05\n",
      "Epoch 52/300\n",
      "12707/12707 [==============================] - 4s 317us/step - loss: 8.6099e-05\n",
      "Epoch 53/300\n",
      "12707/12707 [==============================] - 4s 324us/step - loss: 8.5371e-05\n",
      "Epoch 54/300\n",
      "12707/12707 [==============================] - 4s 327us/step - loss: 8.6062e-05\n",
      "Epoch 55/300\n",
      "12707/12707 [==============================] - 4s 322us/step - loss: 8.4485e-05\n",
      "Epoch 56/300\n",
      "12707/12707 [==============================] - 4s 316us/step - loss: 8.4312e-05\n",
      "Epoch 57/300\n",
      "12707/12707 [==============================] - 4s 323us/step - loss: 8.4142e-05\n",
      "Epoch 58/300\n",
      "12707/12707 [==============================] - 4s 338us/step - loss: 8.3722e-05\n",
      "Epoch 59/300\n",
      "12707/12707 [==============================] - 4s 322us/step - loss: 8.3839e-05\n",
      "Epoch 60/300\n",
      "12707/12707 [==============================] - 4s 318us/step - loss: 8.3433e-05\n",
      "Epoch 61/300\n",
      "12707/12707 [==============================] - 4s 320us/step - loss: 8.2880e-05\n",
      "Epoch 62/300\n",
      "12707/12707 [==============================] - 4s 333us/step - loss: 8.2439e-05\n",
      "Epoch 63/300\n",
      "12707/12707 [==============================] - 4s 324us/step - loss: 8.2544e-05\n",
      "Epoch 64/300\n",
      "12707/12707 [==============================] - 4s 320us/step - loss: 8.2427e-05\n",
      "Epoch 65/300\n",
      "12707/12707 [==============================] - 4s 319us/step - loss: 8.0545e-05\n",
      "Epoch 66/300\n",
      "12707/12707 [==============================] - 4s 331us/step - loss: 8.2693e-05\n",
      "Epoch 67/300\n",
      "12707/12707 [==============================] - 4s 315us/step - loss: 8.1442e-05\n",
      "Epoch 68/300\n",
      "12707/12707 [==============================] - 4s 324us/step - loss: 8.1263e-05\n",
      "Epoch 69/300\n",
      "12707/12707 [==============================] - 4s 315us/step - loss: 8.1016e-05\n",
      "Epoch 70/300\n",
      "12707/12707 [==============================] - 4s 336us/step - loss: 8.1456e-05\n",
      "Epoch 00070: early stopping\n",
      "##########################  Scores of Train Data  ##########################\n",
      "Train set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.008\n",
      "Train set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.010\n",
      "Train set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.931\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Scores of Test1 Data  ##########################\n",
      "Test1 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.008\n",
      "Test1 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.011\n",
      "Test1 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.928\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Scores of Test2 Data  ##########################\n",
      "Test2 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.008\n",
      "Test2 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.009\n",
      "Test2 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.888\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Details  ##########################\n",
      "297.61s elapsed during modeling\n"
     ]
    }
   ],
   "source": [
    "# Early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5, verbose=1)\n",
    "\n",
    "\n",
    "# Model\n",
    "\n",
    "#input_dim = 2048\n",
    "model = KerasRegressor(build_fn=create_model, batch_size=16, epochs=300, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# Training\n",
    "#np.random.seed(123)\n",
    "modeling(train_encoded=train_encoded, test1_encoded=test1_encoded, test2_encoded=test2_encoded, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Epoch 70/300\n",
    "12707/12707 [==============================] - 4s 336us/step - loss: 8.1456e-05\n",
    "Epoch 00070: early stopping\n",
    "##########################  Scores of Train Data  ##########################\n",
    "Train set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.008\n",
    "Train set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.010\n",
    "Train set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.931\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Scores of Test1 Data  ##########################\n",
    "Test1 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.008\n",
    "Test1 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.011\n",
    "Test1 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.928\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Scores of Test2 Data  ##########################\n",
    "Test2 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.008\n",
    "Test2 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.009\n",
    "Test2 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.888\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Details  ##########################\n",
    "297.61s elapsed during modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
