{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final_model_Keras_without_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 1\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']= '0'\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "#tf.random.set_seed(seed_value)\n",
    "# for later versions: \n",
    "tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "from keras import backend as K\n",
    "# session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "# sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "# K.set_session(sess)\n",
    "# for later versions:\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "\n",
    "# Resource\n",
    "# https://stackoverflow.com/questions/45230448/how-to-get-reproducible-result-when-running-keras-with-tensorflow-backend?rq=1\n",
    "# https://stackoverflow.com/questions/32419510/how-to-get-reproducible-results-in-keras/52897216#52897216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "def get_ecfc(smiles_list, radius=2, nBits=2048, useCounts=True):\n",
    "    \"\"\"\n",
    "    Calculates the ECFP fingerprint for given SMILES list\n",
    "    \n",
    "    :param smiles_list: List of SMILES\n",
    "    :type smiles_list: list\n",
    "    :param radius: The ECPF fingerprints radius.\n",
    "    :type radius: int\n",
    "    :param nBits: The number of bits of the fingerprint vector.\n",
    "    :type nBits: int\n",
    "    :param useCounts: Use count vector or bit vector.\n",
    "    :type useCounts: bool\n",
    "    :returns: The calculated ECPF fingerprints for the given SMILES\n",
    "    :rtype: Dataframe\n",
    "    \"\"\"     \n",
    "    \n",
    "    ecfp_fingerprints=[]\n",
    "    erroneous_smiles=[]\n",
    "    for smiles in smiles_list:\n",
    "        mol=Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            ecfp_fingerprints.append([None]*nBits)\n",
    "            erroneous_smiles.append(smiles)\n",
    "        else:\n",
    "            mol=Chem.AddHs(mol)\n",
    "            if useCounts:\n",
    "                ecfp_fingerprints.append(list(AllChem.GetHashedMorganFingerprint(mol, radius, nBits)))  \n",
    "            else:    \n",
    "                ecfp_fingerprints.append(list(AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits).ToBitString()))  \n",
    "    \n",
    "    # Create dataframe of fingerprints\n",
    "    df_ecfp_fingerprints = pd.DataFrame(data = ecfp_fingerprints, index = smiles_list)\n",
    "    # Remove erroneous data\n",
    "    if len(erroneous_smiles)>0:\n",
    "        print(\"The following erroneous SMILES have been found in the data:\\n{}.\\nThe erroneous SMILES will be removed from the data.\".format('\\n'.join(map(str, erroneous_smiles))))           \n",
    "        df_ecfp_fingerprints = df_ecfp_fingerprints.dropna(how='any')    \n",
    "    \n",
    "    return df_ecfp_fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get and Arrange data\n",
    "import pandas as pd\n",
    "df_data= pd.read_csv('all_data.csv')\n",
    "\n",
    "train_data = df_data[df_data['data_type'] == 0]\n",
    "test1_data = df_data[df_data['data_type'] == 1]\n",
    "test2_data = df_data[df_data['data_type'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded = get_ecfc(train_data[\"reactant_smiles\"])\n",
    "test1_encoded = get_ecfc(test1_data[\"reactant_smiles\"])\n",
    "test2_encoded = get_ecfc(test2_data[\"reactant_smiles\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def modeling(train_data, test1_data, test2_data, encoder, model):  - After deciding the list of the smiles\n",
    "\n",
    "def modeling(train_encoded, test1_encoded, test2_encoded, model):\n",
    "    \n",
    "    from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Training\n",
    "    X = train_encoded\n",
    "    y = train_data['reaction_energy']\n",
    "    \n",
    "    model.fit(X.values, y)\n",
    "    \n",
    "    # Predicting\n",
    "    pred_train = model.predict(train_encoded.values)\n",
    "    pred_test1 = model.predict(test1_encoded.values)\n",
    "    pred_test2 = model.predict(test2_encoded.values)\n",
    "    \n",
    "    \n",
    "    # Scores of Train Data \n",
    "    tr_mae = mean_absolute_error(y, pred_train)\n",
    "    tr_rmse = mean_squared_error(y ,pred_train , squared=False)\n",
    "    tr_r2 = r2_score(y, pred_train)\n",
    "    print('##########################  Scores of Train Data  ##########################')\n",
    "    print('Train set MAE of {}: {:.5f}'.format(model, tr_mae))\n",
    "    print('Train set RMSE of {}: {:.5f}'.format(model, tr_rmse))\n",
    "    print('Train set R2 Score of {}: {:.5f}'.format(model, tr_r2))\n",
    "    \n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    \n",
    "    # Test1 Data\n",
    "    test1_mae = mean_absolute_error(test1_data['reaction_energy'], pred_test1)\n",
    "    test1_rmse = mean_squared_error(test1_data['reaction_energy'], pred_test1, squared=False)\n",
    "    test1_r2 = r2_score(test1_data['reaction_energy'], pred_test1)\n",
    "    print('##########################  Scores of Test1 Data  ##########################')\n",
    "    print('Test1 set MAE of {}: {:.5f}'.format(model, test1_mae))\n",
    "    print('Test1 set RMSE of {}: {:.5f}'.format(model, test1_rmse))\n",
    "    print('Test1 set R2 Score of {}: {:.5f}'.format(model, test1_r2))\n",
    "    \n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    \n",
    "    # Test2 Data\n",
    "    test2_mae = mean_absolute_error(test2_data['reaction_energy'], pred_test2)\n",
    "    test2_rmse = mean_squared_error(test2_data['reaction_energy'], pred_test2, squared=False)\n",
    "    test2_r2 = r2_score(test2_data['reaction_energy'], pred_test2)\n",
    "    print('##########################  Scores of Test2 Data  ##########################')\n",
    "    print('Test2 set MAE of {}: {:.5f}'.format(model, test2_mae))\n",
    "    print('Test2 set RMSE of {}: {:.5f}'.format(model, test2_rmse))\n",
    "    print('Test2 set R2 Score of {}: {:.5f}'.format(model, test2_r2))\n",
    "    \n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('##########################  Details  ##########################')\n",
    "    print(f'{elapsed_time:.2f}s elapsed during modeling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIAL RUNNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "def BuildModel(input_dim=None):\n",
    "    \n",
    "    def model():\n",
    "        keras_model = Sequential()\n",
    "        keras_model.add(Dense(128, input_dim=input_dim,activation='relu')) \n",
    "        keras_model.add(Dense(32, activation='relu')) \n",
    "        keras_model.add(Dense(8,activation='relu')) \n",
    "        keras_model.add(Dense(1,activation='linear'))\n",
    "        keras_model.summary()\n",
    "        keras_model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")   \n",
    "        return keras_model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 266,673\n",
      "Trainable params: 266,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "2542/2542 [==============================] - 5s 2ms/step - loss: 3.9472e-04A: 0s - l\n",
      "Epoch 2/10\n",
      "2542/2542 [==============================] - 4s 2ms/step - loss: 1.1237e-04\n",
      "Epoch 3/10\n",
      "2542/2542 [==============================] - 5s 2ms/step - loss: 1.0659e-04\n",
      "Epoch 4/10\n",
      "2542/2542 [==============================] - 7s 3ms/step - loss: 9.9685e-05A: 3s - loss: 8.9369e- - ETA: 3s - loss: 9.096 - ETA: 2s - loss: 8.918 - ETA: 2s - loss:\n",
      "Epoch 5/10\n",
      "2542/2542 [==============================] - 4s 2ms/step - loss: 8.5763e-05- ETA: 3s - loss: 5.5699e - ETA: 3s -  - ETA:  - ETA: 0s - \n",
      "Epoch 6/10\n",
      "2542/2542 [==============================] - 5s 2ms/step - loss: 8.1323e-05\n",
      "Epoch 7/10\n",
      "2542/2542 [==============================] - 6s 2ms/step - loss: 7.0878e-05A: 0s - \n",
      "Epoch 8/10\n",
      "2542/2542 [==============================] - 6s 2ms/step - loss: 6.9101e-05A: 2s - loss: 8.5972e - ETA: 2s - - ETA: 2s - loss:\n",
      "Epoch 9/10\n",
      "2542/2542 [==============================] - 6s 2ms/step - loss: 6.9344e-05A: 5s - loss: 1.1377e-0 - ETA: 5s \n",
      "Epoch 10/10\n",
      "2542/2542 [==============================] - 6s 2ms/step - loss: 6.7145e-05A: 4s - loss - ETA: 3s - loss: 5 - ETA: 3s - loss: 5.6177 - ETA: 2s - loss: 5.4331 - E - ETA: 1s -  - ETA: 0s - loss: 6.2758 - ETA: 0s - loss: 6.7822e-\n",
      "##########################  Scores of Train Data  ##########################\n",
      "Train set MAE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000002A1B8B1EBC8>: 0.00371\n",
      "Train set RMSE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000002A1B8B1EBC8>: 0.00709\n",
      "Train set R2 Score of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000002A1B8B1EBC8>: 0.96831\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Scores of Test1 Data  ##########################\n",
      "Test1 set MAE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000002A1B8B1EBC8>: 0.00416\n",
      "Test1 set RMSE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000002A1B8B1EBC8>: 0.00754\n",
      "Test1 set R2 Score of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000002A1B8B1EBC8>: 0.96411\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Scores of Test2 Data  ##########################\n",
      "Test2 set MAE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000002A1B8B1EBC8>: 0.00483\n",
      "Test2 set RMSE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000002A1B8B1EBC8>: 0.00628\n",
      "Test2 set R2 Score of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000002A1B8B1EBC8>: 0.95131\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Details  ##########################\n",
      "55.05s elapsed during modeling\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "#input_dim = 2048\n",
    "#model = KerasRegressor(build_fn=BuildModel(input_dim = 2048), nb_epoch=100, batch_size=3)\n",
    "model = KerasRegressor(build_fn=BuildModel(input_dim = 2048), epochs=10, batch_size=5)\n",
    "\n",
    "\n",
    "# Training\n",
    "#np.random.seed(123)\n",
    "modeling(train_encoded=train_encoded, test1_encoded=test1_encoded, test2_encoded=test2_encoded, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 10/10\n",
    "2542/2542 [==============================] - 12s 5ms/step - loss: 6.7145e-05\n",
    "##########################  Scores of Train Data  ##########################\n",
    "Train set MAE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffafb0fb1d0>: 0.004\n",
    "Train set RMSE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffafb0fb1d0>: 0.007\n",
    "Train set R2 Score of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffafb0fb1d0>: 0.968\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Scores of Test1 Data  ##########################\n",
    "Test1 set MAE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffafb0fb1d0>: 0.004\n",
    "Test1 set RMSE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffafb0fb1d0>: 0.008\n",
    "Test1 set R2 Score of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffafb0fb1d0>: 0.964\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Scores of Test2 Data  ##########################\n",
    "Test2 set MAE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffafb0fb1d0>: 0.005\n",
    "Test2 set RMSE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffafb0fb1d0>: 0.006\n",
    "Test2 set R2 Score of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffafb0fb1d0>: 0.951\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Details  ##########################\n",
    "130.03s elapsed during modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 10/10\n",
    "12707/12707 [==============================] - 15s 1ms/step - loss: 6.3266e-05\n",
    "##########################  Scores of Train Data  ##########################\n",
    "Train set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.004\n",
    "Train set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.007\n",
    "Train set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.967\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Scores of Test1 Data  ##########################\n",
    "Test1 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.004\n",
    "Test1 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.008\n",
    "Test1 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.963\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Scores of Test2 Data  ##########################\n",
    "Test2 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.006\n",
    "Test2 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.008\n",
    "Test2 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E1C92ECCC8>: 0.925\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Details  ##########################\n",
    "140.82s elapsed during modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- This is for after Lasso FS !!!  --------   Final Best: 0.957283 using {'activation': 'sigmoid', 'batch_size': 16, 'dropout_rate': 0.0, 'input_dim': 491, 'learn_rate': 0.1, 'momentum': 0.4, 'optimizer': 'RMSprop'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "# Function to create model, required for KerasClassifier\n",
    "\n",
    "\n",
    "def create_model(optimizer='RMSprop', learn_rate=0.1, momentum=0.4, activation='sigmoid', dropout_rate=0.0):\n",
    "    \n",
    "    keras_model = Sequential()\n",
    "    keras_model.add(Dense(128, input_dim=train_encoded.shape[1], activation=activation))\n",
    "    keras_model.add(Dropout(dropout_rate))\n",
    "    keras_model.add(Dense(32, activation=activation)) \n",
    "    keras_model.add(Dropout(dropout_rate))\n",
    "    keras_model.add(Dense(8,activation=activation)) \n",
    "    keras_model.add(Dropout(dropout_rate))\n",
    "    keras_model.add(Dense(1,activation='linear'))\n",
    "    keras_model.summary()\n",
    "    # Compile model\n",
    "    keras_model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "    return keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 266,673\n",
      "Trainable params: 266,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 9.0826e-04\n",
      "Epoch 2/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.5562e-04\n",
      "Epoch 3/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 1.3082e-04\n",
      "Epoch 4/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 1.1739e-04\n",
      "Epoch 5/300\n",
      "795/795 [==============================] - 6s 8ms/step - loss: 1.0892e-04\n",
      "Epoch 6/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.0293e-04\n",
      "Epoch 7/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 9.9728e-05\n",
      "Epoch 8/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 9.6658e-05\n",
      "Epoch 9/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 9.3491e-05\n",
      "Epoch 10/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 9.1768e-05\n",
      "Epoch 11/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 8.9425e-05\n",
      "Epoch 12/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 8.7866e-05\n",
      "Epoch 13/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 8.5458e-05\n",
      "Epoch 14/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 8.5126e-05\n",
      "Epoch 15/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 8.2571e-05\n",
      "Epoch 16/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 8.2546e-05\n",
      "Epoch 17/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 8.0810e-05\n",
      "Epoch 18/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 7.9496e-05\n",
      "Epoch 19/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 7.9108e-05\n",
      "Epoch 20/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 7.7695e-05\n",
      "Epoch 21/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 7.7704e-05\n",
      "Epoch 22/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 7.7107e-05\n",
      "Epoch 23/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 7.5043e-05\n",
      "Epoch 24/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 7.5552e-05\n",
      "Epoch 25/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 7.4075e-05\n",
      "Epoch 26/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 7.4372e-05\n",
      "Epoch 27/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 7.4152e-05\n",
      "Epoch 28/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 7.3116e-05\n",
      "Epoch 29/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 7.2961e-05\n",
      "Epoch 30/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 7.2337e-05\n",
      "Epoch 31/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 7.1743e-05\n",
      "Epoch 32/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 7.1349e-05\n",
      "Epoch 33/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 7.1057e-05\n",
      "Epoch 34/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 7.0234e-05\n",
      "Epoch 35/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.9640e-05\n",
      "Epoch 36/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.9548e-05\n",
      "Epoch 37/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.9304e-05\n",
      "Epoch 38/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.8177e-05\n",
      "Epoch 39/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 6.7420e-05\n",
      "Epoch 40/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.7756e-05\n",
      "Epoch 41/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 6.7601e-05\n",
      "Epoch 42/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.6835e-05\n",
      "Epoch 43/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.7078e-05\n",
      "Epoch 44/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.7203e-05\n",
      "Epoch 45/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.6764e-05\n",
      "Epoch 46/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.4979e-05\n",
      "Epoch 47/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.4842e-05\n",
      "Epoch 48/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.5434e-05\n",
      "Epoch 49/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.4927e-05\n",
      "Epoch 50/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.5825e-05\n",
      "Epoch 51/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.4576e-05\n",
      "Epoch 52/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.4523e-05\n",
      "Epoch 53/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.5514e-05\n",
      "Epoch 54/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.5355e-05\n",
      "Epoch 55/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.4948e-05\n",
      "Epoch 56/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.4429e-05\n",
      "Epoch 57/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.3916e-05\n",
      "Epoch 58/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.3192e-05\n",
      "Epoch 59/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.2964e-05\n",
      "Epoch 60/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.3897e-05\n",
      "Epoch 61/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.3366e-05\n",
      "Epoch 62/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.3961e-05\n",
      "Epoch 63/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.2413e-05\n",
      "Epoch 64/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.2626e-05\n",
      "Epoch 65/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.2505e-05\n",
      "Epoch 66/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.2947e-05\n",
      "Epoch 67/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.1903e-05\n",
      "Epoch 68/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.1964e-05\n",
      "Epoch 69/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.2447e-05\n",
      "Epoch 70/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.1627e-05\n",
      "Epoch 71/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.1897e-05\n",
      "Epoch 72/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.1676e-05\n",
      "Epoch 73/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.0195e-05\n",
      "Epoch 74/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.0512e-05\n",
      "Epoch 75/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.1306e-05\n",
      "Epoch 76/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.0526e-05\n",
      "Epoch 77/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 6.0227e-05\n",
      "Epoch 78/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.1495e-05\n",
      "Epoch 79/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.0441e-05\n",
      "Epoch 80/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.0781e-05\n",
      "Epoch 81/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.0013e-05\n",
      "Epoch 82/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.9596e-05\n",
      "Epoch 83/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 6.0208e-05\n",
      "Epoch 84/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.8867e-05\n",
      "Epoch 85/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.9587e-05\n",
      "Epoch 86/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.9302e-05\n",
      "Epoch 87/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.9006e-05\n",
      "Epoch 88/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.8747e-05\n",
      "Epoch 89/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.8697e-05\n",
      "Epoch 90/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.8144e-05\n",
      "Epoch 91/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.7880e-05\n",
      "Epoch 92/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.8286e-05\n",
      "Epoch 93/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.7395e-05\n",
      "Epoch 94/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.8063e-05\n",
      "Epoch 95/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.7045e-05\n",
      "Epoch 96/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.6563e-05\n",
      "Epoch 97/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.5989e-05\n",
      "Epoch 98/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.6305e-05\n",
      "Epoch 99/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.5920e-05\n",
      "Epoch 100/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.5822e-05\n",
      "Epoch 101/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 5.5818e-05\n",
      "Epoch 102/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.5809e-05\n",
      "Epoch 103/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.5597e-05\n",
      "Epoch 104/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.4849e-05A: 0s - loss\n",
      "Epoch 105/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.6063e-05\n",
      "Epoch 106/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.5234e-05\n",
      "Epoch 107/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.4579e-05\n",
      "Epoch 108/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.4347e-05\n",
      "Epoch 109/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.5185e-05\n",
      "Epoch 110/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.4504e-05\n",
      "Epoch 111/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.3689e-05\n",
      "Epoch 112/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 5.4329e-05\n",
      "Epoch 113/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.4680e-05\n",
      "Epoch 114/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.3336e-05\n",
      "Epoch 115/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.4144e-05\n",
      "Epoch 116/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.3725e-05\n",
      "Epoch 117/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.3922e-05\n",
      "Epoch 118/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.3805e-05\n",
      "Epoch 119/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.3657e-05\n",
      "Epoch 120/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.3290e-05\n",
      "Epoch 121/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.3279e-05\n",
      "Epoch 122/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.3826e-05\n",
      "Epoch 123/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.3389e-05\n",
      "Epoch 124/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.3624e-05\n",
      "Epoch 125/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.3389e-05\n",
      "Epoch 126/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.3367e-05\n",
      "Epoch 127/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.3531e-05\n",
      "Epoch 128/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.3404e-05\n",
      "Epoch 129/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.2652e-05\n",
      "Epoch 130/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.2774e-05\n",
      "Epoch 131/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.2033e-05\n",
      "Epoch 132/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.2222e-05\n",
      "Epoch 133/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.2574e-05\n",
      "Epoch 134/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.3226e-05\n",
      "Epoch 135/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.2386e-05\n",
      "Epoch 136/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.1740e-05\n",
      "Epoch 137/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.1970e-05\n",
      "Epoch 138/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 5.2986e-05\n",
      "Epoch 139/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.2018e-05\n",
      "Epoch 140/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.1757e-05\n",
      "Epoch 141/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.2780e-05\n",
      "Epoch 142/300\n",
      "795/795 [==============================] - 6s 8ms/step - loss: 5.2207e-05\n",
      "Epoch 143/300\n",
      "795/795 [==============================] - 7s 8ms/step - loss: 5.1118e-05\n",
      "Epoch 144/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.2028e-05\n",
      "Epoch 145/300\n",
      "795/795 [==============================] - 10s 13ms/step - loss: 5.1664e-05\n",
      "Epoch 146/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 5.1767e-05\n",
      "Epoch 147/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.1732e-05\n",
      "Epoch 148/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.1349e-05\n",
      "Epoch 149/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.1840e-05\n",
      "Epoch 150/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 5.1419e-05\n",
      "Epoch 151/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.1681e-05\n",
      "Epoch 152/300\n",
      "795/795 [==============================] - 45s 57ms/step - loss: 5.0741e-05\n",
      "Epoch 153/300\n",
      "795/795 [==============================] - 17s 21ms/step - loss: 5.1202e-05 2s - l\n",
      "Epoch 154/300\n",
      "795/795 [==============================] - 15s 19ms/step - loss: 5.1819e-05\n",
      "Epoch 155/300\n",
      "795/795 [==============================] - 6s 8ms/step - loss: 5.1237e-05\n",
      "Epoch 156/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 5.1306e-05\n",
      "Epoch 157/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 5.0965e-05\n",
      "Epoch 158/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 5.1110e-05\n",
      "Epoch 159/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 5.0961e-05\n",
      "Epoch 160/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.1311e-05\n",
      "Epoch 161/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.0726e-05\n",
      "Epoch 162/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.0919e-05\n",
      "Epoch 163/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 5.0266e-05\n",
      "Epoch 164/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 4.9662e-05\n",
      "Epoch 165/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.9781e-05\n",
      "Epoch 166/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.9168e-05\n",
      "Epoch 167/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 4.9560e-05\n",
      "Epoch 168/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.9024e-05\n",
      "Epoch 169/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 4.9900e-05\n",
      "Epoch 170/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.8710e-05\n",
      "Epoch 171/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.9527e-05\n",
      "Epoch 172/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.9146e-05\n",
      "Epoch 173/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.9454e-05\n",
      "Epoch 174/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.8280e-05\n",
      "Epoch 175/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.9041e-05\n",
      "Epoch 176/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.7500e-05\n",
      "Epoch 177/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.8127e-05\n",
      "Epoch 178/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.8384e-05\n",
      "Epoch 179/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.7773e-05\n",
      "Epoch 180/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.7547e-05\n",
      "Epoch 181/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.7295e-05\n",
      "Epoch 182/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.8043e-05\n",
      "Epoch 183/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.7761e-05\n",
      "Epoch 184/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.6936e-05\n",
      "Epoch 185/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.7491e-05\n",
      "Epoch 186/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.7097e-05\n",
      "Epoch 187/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.6922e-05\n",
      "Epoch 188/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.7905e-05\n",
      "Epoch 189/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.7488e-05\n",
      "Epoch 190/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.8256e-05\n",
      "Epoch 191/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 4.6867e-05\n",
      "Epoch 192/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.7150e-05\n",
      "Epoch 193/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 4.6195e-05\n",
      "Epoch 194/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 4.6051e-05\n",
      "Epoch 195/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.5638e-05\n",
      "Epoch 196/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.6937e-05\n",
      "Epoch 197/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.5827e-05\n",
      "Epoch 198/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.7106e-05\n",
      "Epoch 199/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.6640e-05\n",
      "Epoch 200/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.5152e-05\n",
      "Epoch 201/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.5178e-05\n",
      "Epoch 202/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.5753e-05\n",
      "Epoch 203/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 4.5062e-05\n",
      "Epoch 204/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.4499e-05\n",
      "Epoch 205/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.5202e-05\n",
      "Epoch 206/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.4578e-05\n",
      "Epoch 207/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.4084e-05\n",
      "Epoch 208/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 4.3927e-05\n",
      "Epoch 209/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.3548e-05\n",
      "Epoch 210/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.3557e-05\n",
      "Epoch 211/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.3557e-05\n",
      "Epoch 212/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.3937e-05\n",
      "Epoch 213/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.3489e-05\n",
      "Epoch 214/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.2485e-05\n",
      "Epoch 215/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 4.3127e-05\n",
      "Epoch 216/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 4.1641e-05\n",
      "Epoch 217/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.1424e-05\n",
      "Epoch 218/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.1849e-05\n",
      "Epoch 219/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.1553e-05\n",
      "Epoch 220/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.2211e-05\n",
      "Epoch 221/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.1255e-05\n",
      "Epoch 222/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.0146e-05\n",
      "Epoch 223/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.9554e-05\n",
      "Epoch 224/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 4.0536e-05\n",
      "Epoch 225/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 4.0407e-05\n",
      "Epoch 226/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 3.9844e-05\n",
      "Epoch 227/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.9791e-05\n",
      "Epoch 228/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.9647e-05\n",
      "Epoch 229/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.9016e-05\n",
      "Epoch 230/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.9602e-05\n",
      "Epoch 231/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.9291e-05\n",
      "Epoch 232/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.9364e-05\n",
      "Epoch 233/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.7975e-05\n",
      "Epoch 234/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.9507e-05\n",
      "Epoch 235/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.8722e-05\n",
      "Epoch 236/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 3.7955e-05\n",
      "Epoch 237/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.7185e-05\n",
      "Epoch 238/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 3.7785e-05\n",
      "Epoch 239/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 3.7432e-05\n",
      "Epoch 240/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.7122e-05\n",
      "Epoch 241/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.7670e-05\n",
      "Epoch 242/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.7390e-05\n",
      "Epoch 243/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.6543e-05\n",
      "Epoch 244/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.6567e-05\n",
      "Epoch 245/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.6654e-05\n",
      "Epoch 246/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.6283e-05\n",
      "Epoch 247/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.6388e-05\n",
      "Epoch 248/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.6105e-05\n",
      "Epoch 249/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.6443e-05A: 0s - loss: 3.5583\n",
      "Epoch 250/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.6096e-05\n",
      "Epoch 251/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.6379e-05\n",
      "Epoch 252/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.5617e-05\n",
      "Epoch 253/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 3.4469e-05\n",
      "Epoch 254/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.5224e-05\n",
      "Epoch 255/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.4871e-05\n",
      "Epoch 256/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.4734e-05\n",
      "Epoch 257/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.4774e-05\n",
      "Epoch 258/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.4503e-05\n",
      "Epoch 259/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.4131e-05\n",
      "Epoch 260/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 3.4140e-05\n",
      "Epoch 261/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 3.4339e-05\n",
      "Epoch 262/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.4082e-05\n",
      "Epoch 263/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.4770e-05\n",
      "Epoch 264/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.3333e-05\n",
      "Epoch 265/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.4408e-05\n",
      "Epoch 266/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.3844e-05\n",
      "Epoch 267/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.3286e-05\n",
      "Epoch 268/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.4002e-05\n",
      "Epoch 269/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.3183e-05\n",
      "Epoch 270/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.3460e-05\n",
      "Epoch 271/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.2764e-05\n",
      "Epoch 272/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.3676e-05\n",
      "Epoch 273/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.3206e-05\n",
      "Epoch 274/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.2229e-05\n",
      "Epoch 275/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.2569e-05\n",
      "Epoch 276/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.2023e-05\n",
      "Epoch 277/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.2831e-05\n",
      "Epoch 278/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.2272e-05\n",
      "Epoch 279/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.2804e-05\n",
      "Epoch 280/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.2739e-05\n",
      "Epoch 281/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.2046e-05\n",
      "Epoch 282/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.2217e-05\n",
      "Epoch 283/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.2173e-05\n",
      "Epoch 284/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.2059e-05\n",
      "Epoch 285/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.1210e-05\n",
      "Epoch 286/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.1614e-05\n",
      "Epoch 287/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.1552e-05\n",
      "Epoch 288/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.1849e-05\n",
      "Epoch 289/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.1230e-05\n",
      "Epoch 290/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.1768e-05\n",
      "Epoch 291/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.1616e-05\n",
      "Epoch 292/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.0973e-05\n",
      "Epoch 293/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.0712e-05\n",
      "Epoch 294/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.0694e-05\n",
      "Epoch 295/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.0034e-05\n",
      "Epoch 296/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.0821e-05\n",
      "Epoch 297/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.0763e-05\n",
      "Epoch 298/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.0977e-05\n",
      "Epoch 299/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.0635e-05\n",
      "Epoch 300/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 3.0817e-05\n",
      "##########################  Scores of Train Data  ##########################\n",
      "Train set MAE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffac930fc90>: 0.003\n",
      "Train set RMSE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffac930fc90>: 0.005\n",
      "Train set R2 Score of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffac930fc90>: 0.984\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Scores of Test1 Data  ##########################\n",
      "Test1 set MAE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffac930fc90>: 0.004\n",
      "Test1 set RMSE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffac930fc90>: 0.009\n",
      "Test1 set R2 Score of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffac930fc90>: 0.954\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Scores of Test2 Data  ##########################\n",
      "Test2 set MAE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffac930fc90>: 0.084\n",
      "Test2 set RMSE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffac930fc90>: 0.144\n",
      "Test2 set R2 Score of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffac930fc90>: -24.753\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Details  ##########################\n",
      "1588.86s elapsed during modeling\n"
     ]
    }
   ],
   "source": [
    "# Early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=10, verbose=1)\n",
    "\n",
    "\n",
    "# Model\n",
    "\n",
    "#input_dim = 2048\n",
    "#model = KerasRegressor(build_fn=BuildModel(input_dim = 2048), nb_epoch=100, batch_size=3)\n",
    "model = KerasRegressor(build_fn=create_model, batch_size=16, epochs=300, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# Training\n",
    "#np.random.seed(123)\n",
    "modeling(train_encoded=train_encoded, test1_encoded=test1_encoded, test2_encoded=test2_encoded, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem is we optimized for after feature selection. Probably because of the momentum.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "The problem is we optimized for after feature selection.\n",
    "\n",
    "\n",
    "Epoch 242/300\n",
    "12707/12707 [==============================] - 5s 355us/step - loss: 4.1171e-05\n",
    "Epoch 00242: early stopping\n",
    "##########################  Scores of Train Data  ##########################\n",
    "Train set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: 0.003\n",
    "Train set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: 0.005\n",
    "Train set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: 0.981\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Scores of Test1 Data  ##########################\n",
    "Test1 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: 0.004\n",
    "Test1 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: 0.009\n",
    "Test1 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: 0.948\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Scores of Test2 Data  ##########################\n",
    "Test2 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: 0.037\n",
    "Test2 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: 0.082\n",
    "Test2 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002B28E0A0588>: -7.292\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Details  ##########################\n",
    "957.48s elapsed during modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-  Best for without FS ---------------   : 0.956155 using {'activation': 'sigmoid', 'batch_size': 16, 'dropout_rate': 0.1, 'input_dim': 2048, 'learn_rate': 0.05, 'momentum': 0, 'optimizer': 'RMSprop'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "# Function to create model, required for KerasClassifier\n",
    "\n",
    "\n",
    "def create_model(optimizer='RMSprop', learn_rate=0.05, momentum=0, activation='sigmoid', dropout_rate=0.1):\n",
    "    \n",
    "    keras_model = Sequential()\n",
    "    keras_model.add(Dense(128, input_dim=train_encoded.shape[1], activation=activation))\n",
    "    keras_model.add(Dropout(dropout_rate))\n",
    "    keras_model.add(Dense(32, activation=activation)) \n",
    "    keras_model.add(Dropout(dropout_rate))\n",
    "    keras_model.add(Dense(8,activation=activation)) \n",
    "    keras_model.add(Dropout(dropout_rate))\n",
    "    keras_model.add(Dense(1,activation='linear'))\n",
    "    keras_model.summary()\n",
    "    # Compile model\n",
    "    keras_model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "    return keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 266,673\n",
      "Trainable params: 266,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 0.0074\n",
      "Epoch 2/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 2.5964e-04\n",
      "Epoch 3/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.9477e-04\n",
      "Epoch 4/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.6733e-04\n",
      "Epoch 5/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.5123e-04\n",
      "Epoch 6/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 1.4646e-04\n",
      "Epoch 7/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.4033e-04\n",
      "Epoch 8/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.4166e-04\n",
      "Epoch 9/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.3771e-04\n",
      "Epoch 10/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.3231e-04\n",
      "Epoch 11/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 1.3253e-04\n",
      "Epoch 12/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 1.3134e-04\n",
      "Epoch 13/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.2949e-04\n",
      "Epoch 14/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.3187e-04\n",
      "Epoch 15/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.2889e-04\n",
      "Epoch 16/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 1.2664e-04\n",
      "Epoch 17/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.2839e-04\n",
      "Epoch 18/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.2081e-04\n",
      "Epoch 19/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.2484e-04\n",
      "Epoch 20/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.1818e-04\n",
      "Epoch 21/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.1854e-04\n",
      "Epoch 22/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 1.1888e-04\n",
      "Epoch 23/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 1.1930e-04\n",
      "Epoch 24/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.2334e-04\n",
      "Epoch 25/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.1928e-04\n",
      "Epoch 26/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.1855e-04\n",
      "Epoch 27/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 1.1702e-04\n",
      "Epoch 28/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.1614e-04\n",
      "Epoch 29/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 1.1688e-04\n",
      "Epoch 30/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 1.1496e-04\n",
      "Epoch 31/300\n",
      "795/795 [==============================] - 5s 6ms/step - loss: 1.1853e-04\n",
      "Epoch 32/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 1.1496e-04\n",
      "Epoch 33/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.1725e-04\n",
      "Epoch 34/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.1143e-04\n",
      "Epoch 35/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.1479e-04\n",
      "Epoch 36/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.1545e-04\n",
      "Epoch 37/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.1284e-04\n",
      "Epoch 38/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 1.1363e-04\n",
      "Epoch 39/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 1.1133e-04\n",
      "Epoch 40/300\n",
      "795/795 [==============================] - 6s 8ms/step - loss: 1.1133e-04\n",
      "Epoch 41/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 1.1005e-04\n",
      "Epoch 42/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 1.1186e-04\n",
      "Epoch 43/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 1.0946e-04\n",
      "Epoch 44/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 1.1100e-04\n",
      "Epoch 45/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 1.1044e-04\n",
      "Epoch 46/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 1.1403e-04\n",
      "Epoch 47/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 1.0726e-04\n",
      "Epoch 48/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 1.1416e-04\n",
      "Epoch 49/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.0717e-04\n",
      "Epoch 50/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.1166e-04\n",
      "Epoch 51/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.0876e-04\n",
      "Epoch 52/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.1023e-04\n",
      "Epoch 53/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 1.0989e-04\n",
      "Epoch 54/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.1088e-04\n",
      "Epoch 55/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 1.1052e-04\n",
      "Epoch 56/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.0756e-04\n",
      "Epoch 57/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.0786e-04\n",
      "Epoch 58/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.0976e-04\n",
      "Epoch 59/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.0572e-04\n",
      "Epoch 60/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.1134e-04\n",
      "Epoch 61/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.0681e-04\n",
      "Epoch 62/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.0972e-04\n",
      "Epoch 63/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.1003e-04\n",
      "Epoch 64/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.0720e-04\n",
      "Epoch 65/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.0938e-04\n",
      "Epoch 66/300\n",
      "795/795 [==============================] - 6s 8ms/step - loss: 1.0771e-04\n",
      "Epoch 67/300\n",
      "795/795 [==============================] - 6s 7ms/step - loss: 1.0571e-04\n",
      "Epoch 68/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.0271e-04\n",
      "Epoch 69/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.0482e-04\n",
      "Epoch 70/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.0867e-04\n",
      "Epoch 71/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.0650e-04\n",
      "Epoch 72/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.0712e-04\n",
      "Epoch 73/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.0466e-04\n",
      "Epoch 74/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.0569e-04\n",
      "Epoch 75/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.0664e-04\n",
      "Epoch 76/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.0882e-04\n",
      "Epoch 77/300\n",
      "795/795 [==============================] - 6s 8ms/step - loss: 1.0566e-04\n",
      "Epoch 78/300\n",
      "795/795 [==============================] - 5s 7ms/step - loss: 1.0964e-04\n",
      "Epoch 00078: early stopping\n",
      "##########################  Scores of Train Data  ##########################\n",
      "Train set MAE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffaa92b3490>: 0.003\n",
      "Train set RMSE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffaa92b3490>: 0.007\n",
      "Train set R2 Score of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffaa92b3490>: 0.969\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Scores of Test1 Data  ##########################\n",
      "Test1 set MAE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffaa92b3490>: 0.003\n",
      "Test1 set RMSE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffaa92b3490>: 0.008\n",
      "Test1 set R2 Score of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffaa92b3490>: 0.962\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Scores of Test2 Data  ##########################\n",
      "Test2 set MAE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffaa92b3490>: 0.009\n",
      "Test2 set RMSE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffaa92b3490>: 0.012\n",
      "Test2 set R2 Score of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7ffaa92b3490>: 0.832\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Details  ##########################\n",
      "440.43s elapsed during modeling\n"
     ]
    }
   ],
   "source": [
    "# Early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=10, verbose=1)\n",
    "\n",
    "\n",
    "# Model\n",
    "\n",
    "#input_dim = 2048\n",
    "model = KerasRegressor(build_fn=create_model, batch_size=16, epochs=300, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# Training\n",
    "#np.random.seed(123)\n",
    "modeling(train_encoded=train_encoded, test1_encoded=test1_encoded, test2_encoded=test2_encoded, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Epoch 64/300\n",
    "12707/12707 [==============================] - 4s 336us/step - loss: 1.1113e-04\n",
    "Epoch 00064: early stopping\n",
    "##########################  Scores of Train Data  ##########################\n",
    "Train set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.003\n",
    "Train set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.007\n",
    "Train set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.966\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Scores of Test1 Data  ##########################\n",
    "Test1 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.004\n",
    "Test1 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.008\n",
    "Test1 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.961\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Scores of Test2 Data  ##########################\n",
    "Test2 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.008\n",
    "Test2 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.009\n",
    "Test2 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020E73CF5AC8>: 0.893\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Details  ##########################\n",
    "246.22s elapsed during modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------- FINAL MODEL ----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After decreasing patience from 10 to 5..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "# Function to create model, required for KerasClassifier\n",
    "\n",
    "\n",
    "def create_model(optimizer='RMSprop', learn_rate=0.05, momentum=0, activation='sigmoid', dropout_rate=0.1):\n",
    "    \n",
    "    keras_model = Sequential()\n",
    "    keras_model.add(Dense(128, input_dim=train_encoded.shape[1], activation=activation))\n",
    "    keras_model.add(Dropout(dropout_rate))\n",
    "    keras_model.add(Dense(32, activation=activation)) \n",
    "    keras_model.add(Dropout(dropout_rate))\n",
    "    keras_model.add(Dense(8,activation=activation)) \n",
    "    keras_model.add(Dropout(dropout_rate))\n",
    "    keras_model.add(Dense(1,activation='linear'))\n",
    "    keras_model.summary()\n",
    "    # Compile model\n",
    "    keras_model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "    return keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 266,673\n",
      "Trainable params: 266,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/23\n",
      "795/795 [==============================] - 10s 12ms/step - loss: 0.0053\n",
      "Epoch 2/23\n",
      "795/795 [==============================] - 9s 11ms/step - loss: 2.6015e-04\n",
      "Epoch 3/23\n",
      "795/795 [==============================] - 11s 13ms/step - loss: 1.9284e-04\n",
      "Epoch 4/23\n",
      "795/795 [==============================] - 10s 13ms/step - loss: 1.6684e-04\n",
      "Epoch 5/23\n",
      "795/795 [==============================] - 10s 12ms/step - loss: 1.5065e-04\n",
      "Epoch 6/23\n",
      "795/795 [==============================] - 9s 11ms/step - loss: 1.4279e-04: 0s - loss: 1.\n",
      "Epoch 7/23\n",
      "795/795 [==============================] - 8s 10ms/step - loss: 1.3698e-04\n",
      "Epoch 8/23\n",
      "795/795 [==============================] - 7s 9ms/step - loss: 1.3386e-04\n",
      "Epoch 9/23\n",
      "795/795 [==============================] - 10s 12ms/step - loss: 1.3437e-04\n",
      "Epoch 10/23\n",
      "795/795 [==============================] - 10s 12ms/step - loss: 1.3085e-04\n",
      "Epoch 11/23\n",
      "795/795 [==============================] - 8s 10ms/step - loss: 1.3076e-04\n",
      "Epoch 12/23\n",
      "795/795 [==============================] - 9s 12ms/step - loss: 1.2747e-04\n",
      "Epoch 13/23\n",
      "795/795 [==============================] - 9s 11ms/step - loss: 1.2617e-04\n",
      "Epoch 14/23\n",
      "795/795 [==============================] - 8s 10ms/step - loss: 1.2888e-04\n",
      "Epoch 15/23\n",
      "795/795 [==============================] - 8s 10ms/step - loss: 1.2081e-04\n",
      "Epoch 16/23\n",
      "795/795 [==============================] - 10s 12ms/step - loss: 1.2639e-04\n",
      "Epoch 17/23\n",
      "795/795 [==============================] - 10s 12ms/step - loss: 1.2224e-04\n",
      "Epoch 18/23\n",
      "795/795 [==============================] - 9s 12ms/step - loss: 1.2100e-04\n",
      "Epoch 19/23\n",
      "795/795 [==============================] - 9s 12ms/step - loss: 1.2203e-04\n",
      "Epoch 20/23\n",
      "795/795 [==============================] - 8s 11ms/step - loss: 1.1783e-04\n",
      "Epoch 21/23\n",
      "795/795 [==============================] - 9s 11ms/step - loss: 1.2045e-04\n",
      "Epoch 22/23\n",
      "795/795 [==============================] - 8s 10ms/step - loss: 1.2159e-04\n",
      "Epoch 23/23\n",
      "795/795 [==============================] - 8s 11ms/step - loss: 1.1567e-04\n",
      "##########################  Scores of Train Data  ##########################\n",
      "Train set MAE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fd941ecb550>: 0.005\n",
      "Train set RMSE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fd941ecb550>: 0.009\n",
      "Train set R2 Score of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fd941ecb550>: 0.947\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Scores of Test1 Data  ##########################\n",
      "Test1 set MAE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fd941ecb550>: 0.006\n",
      "Test1 set RMSE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fd941ecb550>: 0.009\n",
      "Test1 set R2 Score of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fd941ecb550>: 0.948\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Scores of Test2 Data  ##########################\n",
      "Test2 set MAE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fd941ecb550>: 0.007\n",
      "Test2 set RMSE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fd941ecb550>: 0.009\n",
      "Test2 set R2 Score of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fd941ecb550>: 0.895\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Details  ##########################\n",
      "218.36s elapsed during modeling\n"
     ]
    }
   ],
   "source": [
    "# Epoch 23\n",
    "from keras.callbacks import EarlyStopping\n",
    "#early_stopping = EarlyStopping(monitor='loss', patience=5, verbose=1)\n",
    "\n",
    "\n",
    "# Model\n",
    "\n",
    "#input_dim = 2048\n",
    "model = KerasRegressor(build_fn=create_model, batch_size=16, epochs=23)\n",
    "\n",
    "\n",
    "# Training\n",
    "#np.random.seed(123)\n",
    "modeling(train_encoded=train_encoded, test1_encoded=test1_encoded, test2_encoded=test2_encoded, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 266,673\n",
      "Trainable params: 266,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "795/795 [==============================] - 11s 14ms/step - loss: 0.0053\n",
      "Epoch 2/300\n",
      "795/795 [==============================] - 9s 11ms/step - loss: 2.6015e-04\n",
      "Epoch 3/300\n",
      "795/795 [==============================] - 9s 11ms/step - loss: 1.9284e-04\n",
      "Epoch 4/300\n",
      "795/795 [==============================] - 9s 12ms/step - loss: 1.6684e-04\n",
      "Epoch 5/300\n",
      "795/795 [==============================] - 9s 11ms/step - loss: 1.5065e-04\n",
      "Epoch 6/300\n",
      "795/795 [==============================] - 10s 12ms/step - loss: 1.4279e-04\n",
      "Epoch 7/300\n",
      "795/795 [==============================] - 11s 13ms/step - loss: 1.3698e-04\n",
      "Epoch 8/300\n",
      "795/795 [==============================] - 6s 8ms/step - loss: 1.3386e-04\n",
      "Epoch 9/300\n",
      "795/795 [==============================] - 7s 9ms/step - loss: 1.3437e-04\n",
      "Epoch 10/300\n",
      "795/795 [==============================] - 10s 13ms/step - loss: 1.3085e-04\n",
      "Epoch 11/300\n",
      "795/795 [==============================] - 10s 12ms/step - loss: 1.3076e-04\n",
      "Epoch 12/300\n",
      "795/795 [==============================] - 7s 9ms/step - loss: 1.2747e-04\n",
      "Epoch 13/300\n",
      "795/795 [==============================] - 10s 12ms/step - loss: 1.2617e-04\n",
      "Epoch 14/300\n",
      "795/795 [==============================] - 9s 11ms/step - loss: 1.2888e-04: 0s - loss: \n",
      "Epoch 15/300\n",
      "795/795 [==============================] - 9s 11ms/step - loss: 1.2081e-04\n",
      "Epoch 16/300\n",
      "795/795 [==============================] - 8s 10ms/step - loss: 1.2639e-04\n",
      "Epoch 17/300\n",
      "795/795 [==============================] - 10s 13ms/step - loss: 1.2224e-04\n",
      "Epoch 18/300\n",
      "795/795 [==============================] - 10s 12ms/step - loss: 1.2100e-04\n",
      "Epoch 19/300\n",
      "795/795 [==============================] - 9s 11ms/step - loss: 1.2203e-04\n",
      "Epoch 20/300\n",
      "795/795 [==============================] - 11s 14ms/step - loss: 1.1783e-04\n",
      "Epoch 21/300\n",
      "795/795 [==============================] - 10s 12ms/step - loss: 1.2045e-04\n",
      "Epoch 22/300\n",
      "795/795 [==============================] - 8s 10ms/step - loss: 1.2159e-04\n",
      "Epoch 23/300\n",
      "795/795 [==============================] - 10s 12ms/step - loss: 1.1567e-04\n",
      "Epoch 24/300\n",
      "795/795 [==============================] - 10s 13ms/step - loss: 1.1882e-04\n",
      "Epoch 25/300\n",
      "795/795 [==============================] - 11s 14ms/step - loss: 1.1870e-04 \n",
      "Epoch 26/300\n",
      "795/795 [==============================] - 13s 16ms/step - loss: 1.1807e-04 0s - loss: \n",
      "Epoch 27/300\n",
      "795/795 [==============================] - 11s 14ms/step - loss: 1.1456e-04\n",
      "Epoch 28/300\n",
      "795/795 [==============================] - 9s 12ms/step - loss: 1.1470e-04\n",
      "Epoch 29/300\n",
      "795/795 [==============================] - 9s 11ms/step - loss: 1.1290e-04: 0s - loss: 1.0688e-0 - ETA: 0s - l\n",
      "Epoch 30/300\n",
      "795/795 [==============================] - 10s 13ms/step - loss: 1.1634e-04\n",
      "Epoch 31/300\n",
      "795/795 [==============================] - 9s 11ms/step - loss: 1.1479e-04\n",
      "Epoch 32/300\n",
      "795/795 [==============================] - 9s 11ms/step - loss: 1.1355e-04\n",
      "Epoch 33/300\n",
      "795/795 [==============================] - 7s 9ms/step - loss: 1.1303e-04\n",
      "Epoch 34/300\n",
      "795/795 [==============================] - 7s 8ms/step - loss: 1.1324e-04\n",
      "Epoch 00034: early stopping\n",
      "##########################  Scores of Train Data  ##########################\n",
      "Train set MAE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fc5ebb05a50>: 0.004\n",
      "Train set RMSE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fc5ebb05a50>: 0.008\n",
      "Train set R2 Score of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fc5ebb05a50>: 0.958\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Scores of Test1 Data  ##########################\n",
      "Test1 set MAE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fc5ebb05a50>: 0.005\n",
      "Test1 set RMSE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fc5ebb05a50>: 0.008\n",
      "Test1 set R2 Score of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fc5ebb05a50>: 0.958\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Scores of Test2 Data  ##########################\n",
      "Test2 set MAE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fc5ebb05a50>: 0.006\n",
      "Test2 set RMSE of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fc5ebb05a50>: 0.008\n",
      "Test2 set R2 Score of <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fc5ebb05a50>: 0.928\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Details  ##########################\n",
      "322.94s elapsed during modeling\n"
     ]
    }
   ],
   "source": [
    "# Early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5, verbose=1)\n",
    "\n",
    "\n",
    "# Model\n",
    "\n",
    "#input_dim = 2048\n",
    "model = KerasRegressor(build_fn=create_model, batch_size=16, epochs=300, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# Training\n",
    "#np.random.seed(123)\n",
    "modeling(train_encoded=train_encoded, test1_encoded=test1_encoded, test2_encoded=test2_encoded, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---------------------------- Reproducible (Checked=4) ----------------------------\n",
    "\n",
    "Epoch 22/300\n",
    "12707/12707 [==============================] - 5s 373us/step - loss: 1.2642e-04\n",
    "Epoch 23/300\n",
    "12707/12707 [==============================] - 4s 346us/step - loss: 1.2615e-04\n",
    "Epoch 00023: early stopping\n",
    "##########################  Scores of Train Data  ##########################\n",
    "Train set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000023382BB9408>: 0.004\n",
    "Train set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000023382BB9408>: 0.008\n",
    "Train set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000023382BB9408>: 0.959\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Scores of Test1 Data  ##########################\n",
    "Test1 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000023382BB9408>: 0.004\n",
    "Test1 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000023382BB9408>: 0.008\n",
    "Test1 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000023382BB9408>: 0.962\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Scores of Test2 Data  ##########################\n",
    "Test2 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000023382BB9408>: 0.005\n",
    "Test2 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000023382BB9408>: 0.006\n",
    "Test2 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x0000023382BB9408>: 0.952\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Details  ##########################\n",
    "110.66s elapsed during modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Test 1 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reaction_id</th>\n",
       "      <th>data_package_id</th>\n",
       "      <th>bond_type</th>\n",
       "      <th>functional_group_stoichiometry</th>\n",
       "      <th>reactant_smiles</th>\n",
       "      <th>product_smiles</th>\n",
       "      <th>reactant_inchiKey</th>\n",
       "      <th>product_inchiKey</th>\n",
       "      <th>reactant_solubility</th>\n",
       "      <th>product_solubility</th>\n",
       "      <th>...</th>\n",
       "      <th>product_single_point_job_id</th>\n",
       "      <th>reactant_optimization_job_id</th>\n",
       "      <th>product_optimization_job_id</th>\n",
       "      <th>UMAP-1</th>\n",
       "      <th>UMAP-2</th>\n",
       "      <th>data_type</th>\n",
       "      <th>reactantUFF</th>\n",
       "      <th>reactantMMFF</th>\n",
       "      <th>productUFF</th>\n",
       "      <th>productMMFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>OH</td>\n",
       "      <td>COOH</td>\n",
       "      <td>O=C1CC(=O)C(C(=O)O)=C1C(=O)O</td>\n",
       "      <td>C1C(O)=C(C(=O)O)C(=C1O)C(=O)O</td>\n",
       "      <td>QLGSJNWSAMBDMI-UHFFFAOYSA-N</td>\n",
       "      <td>AEVQXUUICHCAGT-UHFFFAOYSA-N</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.867</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>13.362195</td>\n",
       "      <td>3.405288</td>\n",
       "      <td>1</td>\n",
       "      <td>33.280029</td>\n",
       "      <td>-113.415199</td>\n",
       "      <td>37.053325</td>\n",
       "      <td>-2.716193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>OH</td>\n",
       "      <td>F</td>\n",
       "      <td>O=C1CC(=O)C=C1F</td>\n",
       "      <td>C1C(O)=C(F)C=C1O</td>\n",
       "      <td>XVCHEZRSXGJYDT-UHFFFAOYSA-N</td>\n",
       "      <td>LLYKNQJBRVSOKM-UHFFFAOYSA-N</td>\n",
       "      <td>-0.524</td>\n",
       "      <td>-0.499</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>14.856011</td>\n",
       "      <td>2.316219</td>\n",
       "      <td>1</td>\n",
       "      <td>23.112465</td>\n",
       "      <td>-12.882731</td>\n",
       "      <td>24.103198</td>\n",
       "      <td>34.474933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   reaction_id  data_package_id bond_type functional_group_stoichiometry  \\\n",
       "2            3                1        OH                           COOH   \n",
       "3            4                1        OH                              F   \n",
       "\n",
       "                reactant_smiles                 product_smiles  \\\n",
       "2  O=C1CC(=O)C(C(=O)O)=C1C(=O)O  C1C(O)=C(C(=O)O)C(=C1O)C(=O)O   \n",
       "3               O=C1CC(=O)C=C1F               C1C(O)=C(F)C=C1O   \n",
       "\n",
       "             reactant_inchiKey             product_inchiKey  \\\n",
       "2  QLGSJNWSAMBDMI-UHFFFAOYSA-N  AEVQXUUICHCAGT-UHFFFAOYSA-N   \n",
       "3  XVCHEZRSXGJYDT-UHFFFAOYSA-N  LLYKNQJBRVSOKM-UHFFFAOYSA-N   \n",
       "\n",
       "   reactant_solubility  product_solubility  ...  product_single_point_job_id  \\\n",
       "2               -0.966              -0.867  ...                         26.0   \n",
       "3               -0.524              -0.499  ...                         34.0   \n",
       "\n",
       "   reactant_optimization_job_id  product_optimization_job_id     UMAP-1  \\\n",
       "2                          19.0                         25.0  13.362195   \n",
       "3                          21.0                         33.0  14.856011   \n",
       "\n",
       "     UMAP-2  data_type  reactantUFF  reactantMMFF  productUFF  productMMFF  \n",
       "2  3.405288          1    33.280029   -113.415199   37.053325    -2.716193  \n",
       "3  2.316219          1    23.112465    -12.882731   24.103198    34.474933  \n",
       "\n",
       "[2 rows x 46 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elham/opt/anaconda3/envs/reddb/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reaction_id</th>\n",
       "      <th>reactant_smiles</th>\n",
       "      <th>reaction_energy</th>\n",
       "      <th>pred_test1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>O=C1CC(=O)C(C(=O)O)=C1C(=O)O</td>\n",
       "      <td>-0.06394</td>\n",
       "      <td>-0.036776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>O=C1CC(=O)C=C1F</td>\n",
       "      <td>-0.01642</td>\n",
       "      <td>-0.016908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>O=C1NC(=O)C=C1</td>\n",
       "      <td>-0.00731</td>\n",
       "      <td>-0.002410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>O=C1NC(=O)C(F)=C1F</td>\n",
       "      <td>-0.00118</td>\n",
       "      <td>0.012086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>O=C1SC(=O)C(C(=O)O)=C1C(=O)O</td>\n",
       "      <td>-0.06775</td>\n",
       "      <td>-0.048508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15759</th>\n",
       "      <td>15897</td>\n",
       "      <td>O=S(=O)(O)c(c1)cc(S(=O)(=O)O)c(c12)c(O)n(c2O)N...</td>\n",
       "      <td>-0.00215</td>\n",
       "      <td>0.001814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15762</th>\n",
       "      <td>15900</td>\n",
       "      <td>c1cccc(c12)c(O)n(c2O)N(C3=O)C(=O)c(c34)c(S(=O)...</td>\n",
       "      <td>0.02162</td>\n",
       "      <td>0.004101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15768</th>\n",
       "      <td>15906</td>\n",
       "      <td>O=S(=O)(O)c(c1)c(S(=O)(=O)O)c(S(=O)(=O)O)c(c12...</td>\n",
       "      <td>-0.01803</td>\n",
       "      <td>-0.011120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15788</th>\n",
       "      <td>15927</td>\n",
       "      <td>O=S(=O)(O)c1ccc(S(=O)(=O)O)c(c12)c(O)n(c2O)N(C...</td>\n",
       "      <td>-0.03881</td>\n",
       "      <td>-0.009773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15791</th>\n",
       "      <td>15930</td>\n",
       "      <td>O=S(=O)(O)c1c(S(=O)(=O)O)c(S(=O)(=O)O)c(S(=O)(...</td>\n",
       "      <td>0.00826</td>\n",
       "      <td>-0.020166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1607 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       reaction_id                                    reactant_smiles  \\\n",
       "2                3                       O=C1CC(=O)C(C(=O)O)=C1C(=O)O   \n",
       "3                4                                    O=C1CC(=O)C=C1F   \n",
       "13              14                                     O=C1NC(=O)C=C1   \n",
       "14              15                                 O=C1NC(=O)C(F)=C1F   \n",
       "24              25                       O=C1SC(=O)C(C(=O)O)=C1C(=O)O   \n",
       "...            ...                                                ...   \n",
       "15759        15897  O=S(=O)(O)c(c1)cc(S(=O)(=O)O)c(c12)c(O)n(c2O)N...   \n",
       "15762        15900  c1cccc(c12)c(O)n(c2O)N(C3=O)C(=O)c(c34)c(S(=O)...   \n",
       "15768        15906  O=S(=O)(O)c(c1)c(S(=O)(=O)O)c(S(=O)(=O)O)c(c12...   \n",
       "15788        15927  O=S(=O)(O)c1ccc(S(=O)(=O)O)c(c12)c(O)n(c2O)N(C...   \n",
       "15791        15930  O=S(=O)(O)c1c(S(=O)(=O)O)c(S(=O)(=O)O)c(S(=O)(...   \n",
       "\n",
       "       reaction_energy  pred_test1  \n",
       "2             -0.06394   -0.036776  \n",
       "3             -0.01642   -0.016908  \n",
       "13            -0.00731   -0.002410  \n",
       "14            -0.00118    0.012086  \n",
       "24            -0.06775   -0.048508  \n",
       "...                ...         ...  \n",
       "15759         -0.00215    0.001814  \n",
       "15762          0.02162    0.004101  \n",
       "15768         -0.01803   -0.011120  \n",
       "15788         -0.03881   -0.009773  \n",
       "15791          0.00826   -0.020166  \n",
       "\n",
       "[1607 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test1 = model.predict(test1_encoded.values)\n",
    "keras_result_test1 = test1_data[[\"reaction_id\", \"reactant_smiles\", \"reaction_energy\"]]\n",
    "keras_result_test1[\"pred_test1\"] = pred_test1\n",
    "keras_result_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03677602, -0.01690776, -0.00241038, ..., -0.01112013,\n",
       "       -0.00977266, -0.02016574], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the dataframe\n",
    "keras_result_test1.to_csv('keras_result_test1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Test 2 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reaction_id</th>\n",
       "      <th>data_package_id</th>\n",
       "      <th>bond_type</th>\n",
       "      <th>functional_group_stoichiometry</th>\n",
       "      <th>reactant_smiles</th>\n",
       "      <th>product_smiles</th>\n",
       "      <th>reactant_inchiKey</th>\n",
       "      <th>product_inchiKey</th>\n",
       "      <th>reactant_solubility</th>\n",
       "      <th>product_solubility</th>\n",
       "      <th>...</th>\n",
       "      <th>product_single_point_job_id</th>\n",
       "      <th>reactant_optimization_job_id</th>\n",
       "      <th>product_optimization_job_id</th>\n",
       "      <th>UMAP-1</th>\n",
       "      <th>UMAP-2</th>\n",
       "      <th>data_type</th>\n",
       "      <th>reactantUFF</th>\n",
       "      <th>reactantMMFF</th>\n",
       "      <th>productUFF</th>\n",
       "      <th>productMMFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>769</td>\n",
       "      <td>25</td>\n",
       "      <td>NH</td>\n",
       "      <td>OH</td>\n",
       "      <td>c1cccc(c12)cc(nn2)O</td>\n",
       "      <td>c1cccc(c12)C=C(O)NN2</td>\n",
       "      <td>CXUGAWWYKSOLEL-UHFFFAOYSA-N</td>\n",
       "      <td>BMBWSQWNXPSELG-UHFFFAOYSA-N</td>\n",
       "      <td>-2.080</td>\n",
       "      <td>-2.410</td>\n",
       "      <td>...</td>\n",
       "      <td>2965.0</td>\n",
       "      <td>2369.0</td>\n",
       "      <td>2964.0</td>\n",
       "      <td>21.961576</td>\n",
       "      <td>-2.257458</td>\n",
       "      <td>2</td>\n",
       "      <td>20.955169</td>\n",
       "      <td>18.343820</td>\n",
       "      <td>17.140645</td>\n",
       "      <td>19.530730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>774</td>\n",
       "      <td>25</td>\n",
       "      <td>NH</td>\n",
       "      <td>OH</td>\n",
       "      <td>Oc1cccc(c12)cc(nn2)O</td>\n",
       "      <td>Oc1cccc(c12)C=C(O)NN2</td>\n",
       "      <td>BSAMMELAAJYOKU-UHFFFAOYSA-N</td>\n",
       "      <td>QXPSFNRPQZDOFI-UHFFFAOYSA-N</td>\n",
       "      <td>-2.173</td>\n",
       "      <td>-2.142</td>\n",
       "      <td>...</td>\n",
       "      <td>3339.0</td>\n",
       "      <td>2335.0</td>\n",
       "      <td>3338.0</td>\n",
       "      <td>22.153984</td>\n",
       "      <td>-2.141872</td>\n",
       "      <td>2</td>\n",
       "      <td>22.612127</td>\n",
       "      <td>27.933289</td>\n",
       "      <td>20.633665</td>\n",
       "      <td>23.125357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     reaction_id  data_package_id bond_type functional_group_stoichiometry  \\\n",
       "767          769               25        NH                             OH   \n",
       "772          774               25        NH                             OH   \n",
       "\n",
       "          reactant_smiles         product_smiles            reactant_inchiKey  \\\n",
       "767   c1cccc(c12)cc(nn2)O   c1cccc(c12)C=C(O)NN2  CXUGAWWYKSOLEL-UHFFFAOYSA-N   \n",
       "772  Oc1cccc(c12)cc(nn2)O  Oc1cccc(c12)C=C(O)NN2  BSAMMELAAJYOKU-UHFFFAOYSA-N   \n",
       "\n",
       "                product_inchiKey  reactant_solubility  product_solubility  \\\n",
       "767  BMBWSQWNXPSELG-UHFFFAOYSA-N               -2.080              -2.410   \n",
       "772  QXPSFNRPQZDOFI-UHFFFAOYSA-N               -2.173              -2.142   \n",
       "\n",
       "     ...  product_single_point_job_id  reactant_optimization_job_id  \\\n",
       "767  ...                       2965.0                        2369.0   \n",
       "772  ...                       3339.0                        2335.0   \n",
       "\n",
       "     product_optimization_job_id     UMAP-1    UMAP-2  data_type  reactantUFF  \\\n",
       "767                       2964.0  21.961576 -2.257458          2    20.955169   \n",
       "772                       3338.0  22.153984 -2.141872          2    22.612127   \n",
       "\n",
       "     reactantMMFF  productUFF  productMMFF  \n",
       "767     18.343820   17.140645    19.530730  \n",
       "772     27.933289   20.633665    23.125357  \n",
       "\n",
       "[2 rows x 46 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elham/opt/anaconda3/envs/reddb/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reaction_id</th>\n",
       "      <th>reactant_smiles</th>\n",
       "      <th>reaction_energy</th>\n",
       "      <th>pred_test2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>769</td>\n",
       "      <td>c1cccc(c12)cc(nn2)O</td>\n",
       "      <td>-0.01916</td>\n",
       "      <td>-0.014683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>774</td>\n",
       "      <td>Oc1cccc(c12)cc(nn2)O</td>\n",
       "      <td>-0.01587</td>\n",
       "      <td>-0.011940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>778</td>\n",
       "      <td>c1c(O)ccc(c12)cc(nn2)O</td>\n",
       "      <td>-0.01793</td>\n",
       "      <td>-0.012989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>781</td>\n",
       "      <td>c1cc(O)cc(c12)cc(nn2)O</td>\n",
       "      <td>-0.01559</td>\n",
       "      <td>-0.014196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>783</td>\n",
       "      <td>c1ccc(O)c(c12)cc(nn2)O</td>\n",
       "      <td>-0.01734</td>\n",
       "      <td>-0.014264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14233</th>\n",
       "      <td>14338</td>\n",
       "      <td>O=C(O)c1cc(C(=O)O)c(C(=O)O)c(c12)S/C(C2=O)=C(C...</td>\n",
       "      <td>-0.06081</td>\n",
       "      <td>-0.057355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14234</th>\n",
       "      <td>14339</td>\n",
       "      <td>O=C(O)c1c(C(=O)O)cc(C(=O)O)c(c12)S/C(C2=O)=C(C...</td>\n",
       "      <td>-0.04998</td>\n",
       "      <td>-0.056185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14235</th>\n",
       "      <td>14340</td>\n",
       "      <td>O=C(O)c1c(C(=O)O)cc(C(=O)O)c(c12)S/C(C2=O)=C(C...</td>\n",
       "      <td>-0.05763</td>\n",
       "      <td>-0.053140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14236</th>\n",
       "      <td>14341</td>\n",
       "      <td>O=C(O)c1c(C(=O)O)c(C(=O)O)cc(c12)S/C(C2=O)=C(C...</td>\n",
       "      <td>-0.05533</td>\n",
       "      <td>-0.050017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14237</th>\n",
       "      <td>14342</td>\n",
       "      <td>O=C(O)c1c(C(=O)O)c(C(=O)O)c(C(=O)O)c(c12)S/C(C...</td>\n",
       "      <td>-0.05424</td>\n",
       "      <td>-0.063191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1480 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       reaction_id                                    reactant_smiles  \\\n",
       "767            769                                c1cccc(c12)cc(nn2)O   \n",
       "772            774                               Oc1cccc(c12)cc(nn2)O   \n",
       "776            778                             c1c(O)ccc(c12)cc(nn2)O   \n",
       "779            781                             c1cc(O)cc(c12)cc(nn2)O   \n",
       "781            783                             c1ccc(O)c(c12)cc(nn2)O   \n",
       "...            ...                                                ...   \n",
       "14233        14338  O=C(O)c1cc(C(=O)O)c(C(=O)O)c(c12)S/C(C2=O)=C(C...   \n",
       "14234        14339  O=C(O)c1c(C(=O)O)cc(C(=O)O)c(c12)S/C(C2=O)=C(C...   \n",
       "14235        14340  O=C(O)c1c(C(=O)O)cc(C(=O)O)c(c12)S/C(C2=O)=C(C...   \n",
       "14236        14341  O=C(O)c1c(C(=O)O)c(C(=O)O)cc(c12)S/C(C2=O)=C(C...   \n",
       "14237        14342  O=C(O)c1c(C(=O)O)c(C(=O)O)c(C(=O)O)c(c12)S/C(C...   \n",
       "\n",
       "       reaction_energy  pred_test2  \n",
       "767           -0.01916   -0.014683  \n",
       "772           -0.01587   -0.011940  \n",
       "776           -0.01793   -0.012989  \n",
       "779           -0.01559   -0.014196  \n",
       "781           -0.01734   -0.014264  \n",
       "...                ...         ...  \n",
       "14233         -0.06081   -0.057355  \n",
       "14234         -0.04998   -0.056185  \n",
       "14235         -0.05763   -0.053140  \n",
       "14236         -0.05533   -0.050017  \n",
       "14237         -0.05424   -0.063191  \n",
       "\n",
       "[1480 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test2 = model.predict(test2_encoded.values)\n",
    "keras_result_test2 = test2_data[[\"reaction_id\", \"reactant_smiles\", \"reaction_energy\"]]\n",
    "keras_result_test2[\"pred_test2\"] = pred_test2\n",
    "keras_result_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01468252, -0.01193978, -0.01298879, ..., -0.05313988,\n",
       "       -0.05001696, -0.06319143], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the dataframe\n",
    "keras_result_test2.to_csv('keras_result_test2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor at 0x7fb572f3da50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03677602, -0.01690776, -0.00241038, ..., -0.01112013,\n",
       "       -0.00977266, -0.02016574], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test1 = model.predict(test1_encoded.values)\n",
    "pred_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_model = model.model.to_json()\n",
    "open('keras_final_model_architecture.json', 'w').write(json_model)\n",
    "# saving weights\n",
    "model.model.save_weights('keras_final_model_weights.h5', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasRegressor' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-5a8adf13c269>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"my_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'KerasRegressor' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "model.save(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'BuildModel.<locals>.model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0d50d1fe0949>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'keras_final_model.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moutfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'BuildModel.<locals>.model'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# save\n",
    "#pickle.dump(model, open('keras_final_model.txt', \"wb\"))\n",
    "\n",
    "filename = 'keras_final_model.txt'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(model,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Saved model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7fb5634bd050>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load\n",
    "#keras_final_model = pickle.load(open(r'.\\final_models\\keras_final_model.txt', \"rb\"))\n",
    "#keras_final_model\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "keras_final_model = model_from_json(open('keras_final_model_architecture.json').read())\n",
    "keras_final_model.load_weights('keras_final_model_weights.h5')\n",
    "keras_final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03677602],\n",
       "       [-0.01690776],\n",
       "       [-0.00241038],\n",
       "       ...,\n",
       "       [-0.01112013],\n",
       "       [-0.00977266],\n",
       "       [-0.02016574]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_pred_test1 = keras_final_model.predict(test1_encoded.values)\n",
    "s_pred_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After deleting last dropout layer...  DIDN'T WORK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "# Function to create model, required for KerasClassifier\n",
    "\n",
    "\n",
    "def create_model(optimizer='RMSprop', learn_rate=0.05, momentum=0, activation='sigmoid', dropout_rate=0.1):\n",
    "    \n",
    "    keras_model = Sequential()\n",
    "    keras_model.add(Dense(128, input_dim=train_encoded.shape[1], activation=activation))\n",
    "    keras_model.add(Dropout(dropout_rate))\n",
    "    keras_model.add(Dense(32, activation=activation)) \n",
    "    keras_model.add(Dropout(dropout_rate))\n",
    "    keras_model.add(Dense(8,activation=activation)) \n",
    "    keras_model.add(Dense(1,activation='linear'))\n",
    "    keras_model.summary()\n",
    "    # Compile model\n",
    "    keras_model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "    return keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 266,673\n",
      "Trainable params: 266,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/300\n",
      "12707/12707 [==============================] - 4s 341us/step - loss: 0.0058\n",
      "Epoch 2/300\n",
      "12707/12707 [==============================] - 4s 340us/step - loss: 2.7221e-04\n",
      "Epoch 3/300\n",
      "12707/12707 [==============================] - 4s 331us/step - loss: 1.9975e-04\n",
      "Epoch 4/300\n",
      "12707/12707 [==============================] - 4s 329us/step - loss: 1.7347e-04\n",
      "Epoch 5/300\n",
      "12707/12707 [==============================] - 4s 350us/step - loss: 1.6041e-04\n",
      "Epoch 6/300\n",
      "12707/12707 [==============================] - 5s 365us/step - loss: 1.4558e-04\n",
      "Epoch 7/300\n",
      "12707/12707 [==============================] - 4s 338us/step - loss: 1.3794e-04\n",
      "Epoch 8/300\n",
      "12707/12707 [==============================] - 5s 355us/step - loss: 1.3149e-04\n",
      "Epoch 9/300\n",
      "12707/12707 [==============================] - 4s 349us/step - loss: 1.2732e-04\n",
      "Epoch 10/300\n",
      "12707/12707 [==============================] - 5s 356us/step - loss: 1.2281e-04\n",
      "Epoch 11/300\n",
      "12707/12707 [==============================] - 4s 316us/step - loss: 1.2047e-04\n",
      "Epoch 12/300\n",
      "12707/12707 [==============================] - 4s 320us/step - loss: 1.1994e-04\n",
      "Epoch 13/300\n",
      "12707/12707 [==============================] - 4s 325us/step - loss: 1.1542e-04\n",
      "Epoch 14/300\n",
      "12707/12707 [==============================] - 4s 315us/step - loss: 1.1151e-04\n",
      "Epoch 15/300\n",
      "12707/12707 [==============================] - 4s 316us/step - loss: 1.1175e-04\n",
      "Epoch 16/300\n",
      "12707/12707 [==============================] - 4s 320us/step - loss: 1.0939e-04\n",
      "Epoch 17/300\n",
      "12707/12707 [==============================] - 4s 329us/step - loss: 1.0905e-04\n",
      "Epoch 18/300\n",
      "12707/12707 [==============================] - 4s 313us/step - loss: 1.0562e-04\n",
      "Epoch 19/300\n",
      "12707/12707 [==============================] - 4s 334us/step - loss: 1.0485e-04\n",
      "Epoch 20/300\n",
      "12707/12707 [==============================] - 5s 360us/step - loss: 1.0607e-04\n",
      "Epoch 21/300\n",
      "12707/12707 [==============================] - 5s 366us/step - loss: 1.0202e-04\n",
      "Epoch 22/300\n",
      "12707/12707 [==============================] - 4s 332us/step - loss: 1.0312e-04\n",
      "Epoch 23/300\n",
      "12707/12707 [==============================] - 5s 359us/step - loss: 9.9797e-05\n",
      "Epoch 24/300\n",
      "12707/12707 [==============================] - 4s 347us/step - loss: 9.9648e-05\n",
      "Epoch 25/300\n",
      "12707/12707 [==============================] - 4s 336us/step - loss: 9.8592e-05\n",
      "Epoch 26/300\n",
      "12707/12707 [==============================] - 4s 335us/step - loss: 1.0029e-04\n",
      "Epoch 27/300\n",
      "12707/12707 [==============================] - 4s 321us/step - loss: 9.8575e-05\n",
      "Epoch 28/300\n",
      "12707/12707 [==============================] - 4s 332us/step - loss: 9.5276e-05\n",
      "Epoch 29/300\n",
      "12707/12707 [==============================] - 4s 324us/step - loss: 9.6416e-05\n",
      "Epoch 30/300\n",
      "12707/12707 [==============================] - 4s 323us/step - loss: 9.4941e-05\n",
      "Epoch 31/300\n",
      "12707/12707 [==============================] - 4s 324us/step - loss: 9.3318e-05\n",
      "Epoch 32/300\n",
      "12707/12707 [==============================] - 5s 370us/step - loss: 9.3563e-05\n",
      "Epoch 33/300\n",
      "12707/12707 [==============================] - 4s 325us/step - loss: 9.4691e-05\n",
      "Epoch 34/300\n",
      "12707/12707 [==============================] - 4s 331us/step - loss: 9.1650e-05 0s - loss: 8.6\n",
      "Epoch 35/300\n",
      "12707/12707 [==============================] - 4s 319us/step - loss: 9.1073e-05\n",
      "Epoch 36/300\n",
      "12707/12707 [==============================] - 4s 345us/step - loss: 9.2056e-05\n",
      "Epoch 37/300\n",
      "12707/12707 [==============================] - 4s 349us/step - loss: 9.1848e-05\n",
      "Epoch 38/300\n",
      "12707/12707 [==============================] - 4s 346us/step - loss: 9.0103e-05\n",
      "Epoch 39/300\n",
      "12707/12707 [==============================] - 4s 338us/step - loss: 8.9865e-05\n",
      "Epoch 40/300\n",
      "12707/12707 [==============================] - 5s 368us/step - loss: 9.0332e-05\n",
      "Epoch 41/300\n",
      "12707/12707 [==============================] - 4s 350us/step - loss: 8.9124e-05\n",
      "Epoch 42/300\n",
      "12707/12707 [==============================] - 5s 362us/step - loss: 8.9522e-05\n",
      "Epoch 43/300\n",
      "12707/12707 [==============================] - 4s 347us/step - loss: 8.8348e-05\n",
      "Epoch 44/300\n",
      "12707/12707 [==============================] - 4s 343us/step - loss: 8.9481e-05\n",
      "Epoch 45/300\n",
      "12707/12707 [==============================] - 4s 332us/step - loss: 8.7332e-05\n",
      "Epoch 46/300\n",
      "12707/12707 [==============================] - 4s 314us/step - loss: 8.6612e-05\n",
      "Epoch 47/300\n",
      "12707/12707 [==============================] - 4s 336us/step - loss: 8.7455e-05\n",
      "Epoch 48/300\n",
      "12707/12707 [==============================] - 4s 317us/step - loss: 8.5881e-05\n",
      "Epoch 49/300\n",
      "12707/12707 [==============================] - 4s 317us/step - loss: 8.7344e-05\n",
      "Epoch 50/300\n",
      "12707/12707 [==============================] - 4s 324us/step - loss: 8.6699e-05\n",
      "Epoch 51/300\n",
      "12707/12707 [==============================] - 4s 334us/step - loss: 8.5993e-05\n",
      "Epoch 52/300\n",
      "12707/12707 [==============================] - 4s 317us/step - loss: 8.6099e-05\n",
      "Epoch 53/300\n",
      "12707/12707 [==============================] - 4s 324us/step - loss: 8.5371e-05\n",
      "Epoch 54/300\n",
      "12707/12707 [==============================] - 4s 327us/step - loss: 8.6062e-05\n",
      "Epoch 55/300\n",
      "12707/12707 [==============================] - 4s 322us/step - loss: 8.4485e-05\n",
      "Epoch 56/300\n",
      "12707/12707 [==============================] - 4s 316us/step - loss: 8.4312e-05\n",
      "Epoch 57/300\n",
      "12707/12707 [==============================] - 4s 323us/step - loss: 8.4142e-05\n",
      "Epoch 58/300\n",
      "12707/12707 [==============================] - 4s 338us/step - loss: 8.3722e-05\n",
      "Epoch 59/300\n",
      "12707/12707 [==============================] - 4s 322us/step - loss: 8.3839e-05\n",
      "Epoch 60/300\n",
      "12707/12707 [==============================] - 4s 318us/step - loss: 8.3433e-05\n",
      "Epoch 61/300\n",
      "12707/12707 [==============================] - 4s 320us/step - loss: 8.2880e-05\n",
      "Epoch 62/300\n",
      "12707/12707 [==============================] - 4s 333us/step - loss: 8.2439e-05\n",
      "Epoch 63/300\n",
      "12707/12707 [==============================] - 4s 324us/step - loss: 8.2544e-05\n",
      "Epoch 64/300\n",
      "12707/12707 [==============================] - 4s 320us/step - loss: 8.2427e-05\n",
      "Epoch 65/300\n",
      "12707/12707 [==============================] - 4s 319us/step - loss: 8.0545e-05\n",
      "Epoch 66/300\n",
      "12707/12707 [==============================] - 4s 331us/step - loss: 8.2693e-05\n",
      "Epoch 67/300\n",
      "12707/12707 [==============================] - 4s 315us/step - loss: 8.1442e-05\n",
      "Epoch 68/300\n",
      "12707/12707 [==============================] - 4s 324us/step - loss: 8.1263e-05\n",
      "Epoch 69/300\n",
      "12707/12707 [==============================] - 4s 315us/step - loss: 8.1016e-05\n",
      "Epoch 70/300\n",
      "12707/12707 [==============================] - 4s 336us/step - loss: 8.1456e-05\n",
      "Epoch 00070: early stopping\n",
      "##########################  Scores of Train Data  ##########################\n",
      "Train set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.008\n",
      "Train set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.010\n",
      "Train set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.931\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Scores of Test1 Data  ##########################\n",
      "Test1 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.008\n",
      "Test1 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.011\n",
      "Test1 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.928\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Scores of Test2 Data  ##########################\n",
      "Test2 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.008\n",
      "Test2 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.009\n",
      "Test2 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.888\n",
      "----------------------------------------------------------------------------\n",
      "##########################  Details  ##########################\n",
      "297.61s elapsed during modeling\n"
     ]
    }
   ],
   "source": [
    "# Early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5, verbose=1)\n",
    "\n",
    "\n",
    "# Model\n",
    "\n",
    "#input_dim = 2048\n",
    "model = KerasRegressor(build_fn=create_model, batch_size=16, epochs=300, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# Training\n",
    "#np.random.seed(123)\n",
    "modeling(train_encoded=train_encoded, test1_encoded=test1_encoded, test2_encoded=test2_encoded, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Epoch 70/300\n",
    "12707/12707 [==============================] - 4s 336us/step - loss: 8.1456e-05\n",
    "Epoch 00070: early stopping\n",
    "##########################  Scores of Train Data  ##########################\n",
    "Train set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.008\n",
    "Train set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.010\n",
    "Train set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.931\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Scores of Test1 Data  ##########################\n",
    "Test1 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.008\n",
    "Test1 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.011\n",
    "Test1 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.928\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Scores of Test2 Data  ##########################\n",
    "Test2 set MAE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.008\n",
    "Test2 set RMSE of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.009\n",
    "Test2 set R2 Score of <keras.wrappers.scikit_learn.KerasRegressor object at 0x000002004C7672C8>: 0.888\n",
    "----------------------------------------------------------------------------\n",
    "##########################  Details  ##########################\n",
    "297.61s elapsed during modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
